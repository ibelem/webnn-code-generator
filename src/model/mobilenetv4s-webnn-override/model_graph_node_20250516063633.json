{
  "identifier": "model_fp16.onnx",
  "format": "ONNX v9",
  "producer": "pytorch 2.3.0",
  "version": "0",
  "functions": [],
  "imports": [
    "ai.onnx v12"
  ],
  "metadata": [],
  "graph": [
    {
      "name": "main_graph",
      "inputs": [
        {
          "name": "pixel_values",
          "value": [
            {
              "name": "pixel_values",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    "batch_size",
                    "num_channels",
                    "height",
                    "width"
                  ]
                }
              }
            }
          ]
        }
      ],
      "outputs": [
        {
          "name": "logits",
          "value": [
            {
              "name": "logits",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    "batch_size",
                    1000
                  ]
                }
              }
            }
          ]
        }
      ],
      "nodes": [
        {
          "name": "graph_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "pixel_values",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        "num_channels",
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "graph_input_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        "num_channels",
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "/conv_stem/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "graph_input_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        "num_channels",
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_415",
                  "initializer": {
                    "name": "onnx::Conv_415",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          3,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        3,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_416",
                  "initializer": {
                    "name": "onnx::Conv_416",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/conv_stem/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(height/2 - 1/2) + 1",
                        "floor(width/2 - 1/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/bn1/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/conv_stem/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(height/2 - 1/2) + 1",
                        "floor(width/2 - 1/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(height/2 - 1/2) + 1",
                        "floor(width/2 - 1/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.0/blocks.0.0/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(height/2 - 1/2) + 1",
                        "floor(width/2 - 1/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_418",
                  "initializer": {
                    "name": "onnx::Conv_418",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          32,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        32,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_419",
                  "initializer": {
                    "name": "onnx::Conv_419",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.0/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.0/blocks.0.0/bn1/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.0/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.0/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.0/blocks.0.1/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.0/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_421",
                  "initializer": {
                    "name": "onnx::Conv_421",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_422",
                  "initializer": {
                    "name": "onnx::Conv_422",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.1/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.0/blocks.0.1/bn1/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.1/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.1/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.1/blocks.1.0/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.0/blocks.0.1/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "floor(floor(height/2 - 1/2)/2) + 1",
                        "floor(floor(width/2 - 1/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_424",
                  "initializer": {
                    "name": "onnx::Conv_424",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          32,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        32,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_425",
                  "initializer": {
                    "name": "onnx::Conv_425",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.0/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.1/blocks.1.0/bn1/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.0/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.0/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.1/blocks.1.1/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.0/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_427",
                  "initializer": {
                    "name": "onnx::Conv_427",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_428",
                  "initializer": {
                    "name": "onnx::Conv_428",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.1/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.1/blocks.1.1/bn1/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.1/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.1/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.0/dw_start/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.1/blocks.1.1/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_430",
                  "initializer": {
                    "name": "onnx::Conv_430",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_431",
                  "initializer": {
                    "name": "onnx::Conv_431",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "64"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.0/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_433",
                  "initializer": {
                    "name": "onnx::Conv_433",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_434",
                  "initializer": {
                    "name": "onnx::Conv_434",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.0/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.0/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(height/2 - 1/2)/2)/2) + 1",
                        "floor(floor(floor(width/2 - 1/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_436",
                  "initializer": {
                    "name": "onnx::Conv_436",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_437",
                  "initializer": {
                    "name": "onnx::Conv_437",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.0/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.0/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_439",
                  "initializer": {
                    "name": "onnx::Conv_439",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_440",
                  "initializer": {
                    "name": "onnx::Conv_440",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.1/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_442",
                  "initializer": {
                    "name": "onnx::Conv_442",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_443",
                  "initializer": {
                    "name": "onnx::Conv_443",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.1/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.1/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_445",
                  "initializer": {
                    "name": "onnx::Conv_445",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_446",
                  "initializer": {
                    "name": "onnx::Conv_446",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.1/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.1/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_448",
                  "initializer": {
                    "name": "onnx::Conv_448",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_449",
                  "initializer": {
                    "name": "onnx::Conv_449",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.1/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.0/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.2/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_451",
                  "initializer": {
                    "name": "onnx::Conv_451",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_452",
                  "initializer": {
                    "name": "onnx::Conv_452",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.2/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.2/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_454",
                  "initializer": {
                    "name": "onnx::Conv_454",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_455",
                  "initializer": {
                    "name": "onnx::Conv_455",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.2/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.2/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_457",
                  "initializer": {
                    "name": "onnx::Conv_457",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_458",
                  "initializer": {
                    "name": "onnx::Conv_458",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.2/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.1/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.3/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_460",
                  "initializer": {
                    "name": "onnx::Conv_460",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_461",
                  "initializer": {
                    "name": "onnx::Conv_461",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.3/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.3/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_463",
                  "initializer": {
                    "name": "onnx::Conv_463",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_464",
                  "initializer": {
                    "name": "onnx::Conv_464",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.3/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.3/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_466",
                  "initializer": {
                    "name": "onnx::Conv_466",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_467",
                  "initializer": {
                    "name": "onnx::Conv_467",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.3/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.2/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.4/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_469",
                  "initializer": {
                    "name": "onnx::Conv_469",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_470",
                  "initializer": {
                    "name": "onnx::Conv_470",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.4/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.4/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_472",
                  "initializer": {
                    "name": "onnx::Conv_472",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_473",
                  "initializer": {
                    "name": "onnx::Conv_473",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.4/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.4/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_475",
                  "initializer": {
                    "name": "onnx::Conv_475",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_476",
                  "initializer": {
                    "name": "onnx::Conv_476",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.4/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.3/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.5/dw_start/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_478",
                  "initializer": {
                    "name": "onnx::Conv_478",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_479",
                  "initializer": {
                    "name": "onnx::Conv_479",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "96"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.5/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_481",
                  "initializer": {
                    "name": "onnx::Conv_481",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_482",
                  "initializer": {
                    "name": "onnx::Conv_482",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.5/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.5/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_484",
                  "initializer": {
                    "name": "onnx::Conv_484",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_485",
                  "initializer": {
                    "name": "onnx::Conv_485",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.2/blocks.2.5/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.4/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.0/dw_start/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.2/blocks.2.5/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_487",
                  "initializer": {
                    "name": "onnx::Conv_487",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_488",
                  "initializer": {
                    "name": "onnx::Conv_488",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "96"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.0/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_490",
                  "initializer": {
                    "name": "onnx::Conv_490",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_491",
                  "initializer": {
                    "name": "onnx::Conv_491",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.0/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.0/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_493",
                  "initializer": {
                    "name": "onnx::Conv_493",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_494",
                  "initializer": {
                    "name": "onnx::Conv_494",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "576"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.0/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.0/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_496",
                  "initializer": {
                    "name": "onnx::Conv_496",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128,
                          576,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128,
                        576,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_497",
                  "initializer": {
                    "name": "onnx::Conv_497",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.1/dw_start/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_499",
                  "initializer": {
                    "name": "onnx::Conv_499",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_500",
                  "initializer": {
                    "name": "onnx::Conv_500",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "128"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.1/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/dw_start/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_502",
                  "initializer": {
                    "name": "onnx::Conv_502",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_503",
                  "initializer": {
                    "name": "onnx::Conv_503",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.1/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.1/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_505",
                  "initializer": {
                    "name": "onnx::Conv_505",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_506",
                  "initializer": {
                    "name": "onnx::Conv_506",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "512"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.1/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.1/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_508",
                  "initializer": {
                    "name": "onnx::Conv_508",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128,
                          512,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128,
                        512,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_509",
                  "initializer": {
                    "name": "onnx::Conv_509",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.1/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.0/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.2/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_511",
                  "initializer": {
                    "name": "onnx::Conv_511",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_512",
                  "initializer": {
                    "name": "onnx::Conv_512",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.2/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.2/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_514",
                  "initializer": {
                    "name": "onnx::Conv_514",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_515",
                  "initializer": {
                    "name": "onnx::Conv_515",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "512"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.2/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.2/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_517",
                  "initializer": {
                    "name": "onnx::Conv_517",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128,
                          512,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128,
                        512,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_518",
                  "initializer": {
                    "name": "onnx::Conv_518",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.2/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.1/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.3/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_520",
                  "initializer": {
                    "name": "onnx::Conv_520",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_521",
                  "initializer": {
                    "name": "onnx::Conv_521",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.3/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.3/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_523",
                  "initializer": {
                    "name": "onnx::Conv_523",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_524",
                  "initializer": {
                    "name": "onnx::Conv_524",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.3/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.3/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_526",
                  "initializer": {
                    "name": "onnx::Conv_526",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_527",
                  "initializer": {
                    "name": "onnx::Conv_527",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.3/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.2/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.4/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_529",
                  "initializer": {
                    "name": "onnx::Conv_529",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_530",
                  "initializer": {
                    "name": "onnx::Conv_530",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.4/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.4/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_532",
                  "initializer": {
                    "name": "onnx::Conv_532",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_533",
                  "initializer": {
                    "name": "onnx::Conv_533",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "512"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.4/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.4/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_535",
                  "initializer": {
                    "name": "onnx::Conv_535",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128,
                          512,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128,
                        512,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_536",
                  "initializer": {
                    "name": "onnx::Conv_536",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.4/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.3/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.5/pw_exp/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_538",
                  "initializer": {
                    "name": "onnx::Conv_538",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_539",
                  "initializer": {
                    "name": "onnx::Conv_539",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.5/pw_exp/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/pw_exp/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.5/dw_mid/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/pw_exp/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_541",
                  "initializer": {
                    "name": "onnx::Conv_541",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_542",
                  "initializer": {
                    "name": "onnx::Conv_542",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          512
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        512
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "512"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.5/dw_mid/bn/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/dw_mid/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.5/pw_proj/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/dw_mid/bn/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        512,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_544",
                  "initializer": {
                    "name": "onnx::Conv_544",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128,
                          512,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128,
                        512,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_545",
                  "initializer": {
                    "name": "onnx::Conv_545",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.3/blocks.3.5/Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/pw_proj/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.4/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "/blocks/blocks.4/blocks.4.0/conv/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.3/blocks.3.5/Add_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        128,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_547",
                  "initializer": {
                    "name": "onnx::Conv_547",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_548",
                  "initializer": {
                    "name": "onnx::Conv_548",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.4/blocks.4.0/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/blocks/blocks.4/blocks.4.0/bn1/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.4/blocks.4.0/conv/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/blocks/blocks.4/blocks.4.0/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/global_pool/pool/GlobalAveragePool",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/blocks/blocks.4/blocks.4.0/bn1/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "floor(floor(floor(floor(floor(height/2 - 1/2)/2)/2)/2)/2) + 1",
                        "floor(floor(floor(floor(floor(width/2 - 1/2)/2)/2)/2)/2) + 1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/global_pool/pool/GlobalAveragePool_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "/conv_head/Conv",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/global_pool/pool/GlobalAveragePool_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "onnx::Conv_550",
                  "initializer": {
                    "name": "onnx::Conv_550",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1280,
                          960,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1280,
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "onnx::Conv_551",
                  "initializer": {
                    "name": "onnx::Conv_551",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1280
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1280
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/conv_head/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "/norm_head/act/Relu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "/conv_head/Conv_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "/norm_head/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "/flatten/Flatten",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "/norm_head/act/Relu_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "/flatten/Flatten_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Flatten",
            "module": "ai.onnx",
            "version": 11,
            "description": "Flattens the input tensor into a 2D matrix. If input tensor has shape\n(d_0, d_1, ... d_n) then the output will have shape\n(d_0 X d_1 ... d_(axis-1), d_axis X d_(axis+1) ... X dn).\n",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value means counting dimensions from the back. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). "
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "A tensor of rank >= axis."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "flatten",
                "code": "shape = (2, 3, 4, 5)\na = np.random.random_sample(shape).astype(np.float32)\n\nfor i in range(len(shape)):\n    node = onnx.helper.make_node(\n        \"Flatten\",\n        inputs=[\"a\"],\n        outputs=[\"b\"],\n        axis=i,\n    )\n\n    new_shape = (1, -1) if i == 0 else (np.prod(shape[0:i]).astype(int), -1)\n    b = np.reshape(a, new_shape)\n    expect(node, inputs=[a], outputs=[b], name=\"test_flatten_axis\" + str(i))"
              },
              {
                "summary": "flatten_negative_axis",
                "code": "shape = (2, 3, 4, 5)\na = np.random.random_sample(shape).astype(np.float32)\n\nfor i in range(-len(shape), 0):\n    node = onnx.helper.make_node(\n        \"Flatten\",\n        inputs=[\"a\"],\n        outputs=[\"b\"],\n        axis=i,\n    )\n\n    new_shape = (np.prod(shape[0:i]).astype(int), -1)\n    b = np.reshape(a, new_shape)\n    expect(\n        node,\n        inputs=[a],\n        outputs=[b],\n        name=\"test_flatten_negative_axis\" + str(abs(i)),\n    )"
              },
              {
                "summary": "flatten_with_default_axis",
                "code": "node = onnx.helper.make_node(\n    \"Flatten\",\n    inputs=[\"a\"],\n    outputs=[\"b\"],  # Default value for axis: axis=1\n)\n\nshape = (5, 4, 3, 2)\na = np.random.random_sample(shape).astype(np.float32)\nnew_shape = (5, 24)\nb = np.reshape(a, new_shape)\nexpect(node, inputs=[a], outputs=[b], name=\"test_flatten_default_axis\")"
              }
            ],
            "category": "Shape"
          }
        },
        {
          "name": "/classifier/Gemm",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "/flatten/Flatten_output_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "classifier.weight",
                  "initializer": {
                    "name": "classifier.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1000,
                          1280
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1000,
                        1280
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "C",
              "value": [
                {
                  "name": "classifier.bias",
                  "initializer": {
                    "name": "classifier.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1000
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1000
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "graph_output_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1000
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "alpha",
              "type": "float32",
              "value": 1
            },
            {
              "name": "beta",
              "type": "float32",
              "value": 1
            },
            {
              "name": "transB",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Gemm",
            "module": "ai.onnx",
            "version": 11,
            "description": "General Matrix multiplication:\nhttps://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3\n\nA' = transpose(A) if transA else A\n\nB' = transpose(B) if transB else B\n\nCompute Y = alpha * A' * B' + beta * C, where input tensor A has shape (M, K) or (K, M),\ninput tensor B has shape (K, N) or (N, K), input tensor C is broadcastable to shape (M, N),\nand output tensor Y has shape (M, N). A will be transposed before doing the\ncomputation if attribute transA is non-zero, same for B and transB.\nThis operator supports **unidirectional broadcasting** (tensor C should be unidirectional broadcastable to tensor A * B); for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "alpha",
                "type": "float32",
                "required": false,
                "default": 1,
                "description": "Scalar multiplier for the product of input tensors A * B."
              },
              {
                "name": "beta",
                "type": "float32",
                "required": false,
                "default": 1,
                "description": "Scalar multiplier for input tensor C."
              },
              {
                "name": "transA",
                "type": "int64",
                "required": false,
                "description": "Whether A should be transposed"
              },
              {
                "name": "transB",
                "type": "int64",
                "required": false,
                "description": "Whether B should be transposed"
              }
            ],
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero."
              },
              {
                "name": "C",
                "type": "T",
                "option": "optional",
                "description": "Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N)."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor of shape (M, N)."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float/int tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "all_attributes",
                "code": "node = onnx.helper.make_node(\n    \"Gemm\",\n    inputs=[\"a\", \"b\", \"c\"],\n    outputs=[\"y\"],\n    alpha=0.25,\n    beta=0.35,\n    transA=1,\n    transB=1,\n)\na = np.random.ranf([4, 3]).astype(np.float32)\nb = np.random.ranf([5, 4]).astype(np.float32)\nc = np.random.ranf([1, 5]).astype(np.float32)\ny = gemm_reference_implementation(\n    a, b, c, transA=1, transB=1, alpha=0.25, beta=0.35\n)\nexpect(node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_all_attributes\")"
              },
              {
                "summary": "alpha",
                "code": "node = onnx.helper.make_node(\n    \"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"], alpha=0.5\n)\na = np.random.ranf([3, 5]).astype(np.float32)\nb = np.random.ranf([5, 4]).astype(np.float32)\nc = np.zeros([1, 4]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c, alpha=0.5)\nexpect(node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_alpha\")"
              },
              {
                "summary": "beta",
                "code": "node = onnx.helper.make_node(\n    \"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"], beta=0.5\n)\na = np.random.ranf([2, 7]).astype(np.float32)\nb = np.random.ranf([7, 4]).astype(np.float32)\nc = np.random.ranf([1, 4]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c, beta=0.5)\nexpect(node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_beta\")"
              },
              {
                "summary": "default_matrix_bias",
                "code": "node = onnx.helper.make_node(\"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"])\na = np.random.ranf([3, 6]).astype(np.float32)\nb = np.random.ranf([6, 4]).astype(np.float32)\nc = np.random.ranf([3, 4]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c)\nexpect(\n    node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_default_matrix_bias\"\n)"
              },
              {
                "summary": "default_no_bias",
                "code": "node = onnx.helper.make_node(\"Gemm\", inputs=[\"a\", \"b\"], outputs=[\"y\"])\na = np.random.ranf([2, 10]).astype(np.float32)\nb = np.random.ranf([10, 3]).astype(np.float32)\ny = gemm_reference_implementation(a, b)\nexpect(node, inputs=[a, b], outputs=[y], name=\"test_gemm_default_no_bias\")"
              },
              {
                "summary": "default_scalar_bias",
                "code": "node = onnx.helper.make_node(\"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"])\na = np.random.ranf([2, 3]).astype(np.float32)\nb = np.random.ranf([3, 4]).astype(np.float32)\nc = np.array(3.14).astype(np.float32)\ny = gemm_reference_implementation(a, b, c)\nexpect(\n    node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_default_scalar_bias\"\n)"
              },
              {
                "summary": "default_single_elem_vector_bias",
                "code": "node = onnx.helper.make_node(\"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"])\na = np.random.ranf([3, 7]).astype(np.float32)\nb = np.random.ranf([7, 3]).astype(np.float32)\nc = np.random.ranf([1]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c)\nexpect(\n    node,\n    inputs=[a, b, c],\n    outputs=[y],\n    name=\"test_gemm_default_single_elem_vector_bias\",\n)"
              },
              {
                "summary": "default_vector_bias",
                "code": "node = onnx.helper.make_node(\"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"])\na = np.random.ranf([2, 7]).astype(np.float32)\nb = np.random.ranf([7, 4]).astype(np.float32)\nc = np.random.ranf([1, 4]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c)\nexpect(\n    node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_default_vector_bias\"\n)"
              },
              {
                "summary": "default_zero_bias",
                "code": "node = onnx.helper.make_node(\"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"])\na = np.random.ranf([3, 5]).astype(np.float32)\nb = np.random.ranf([5, 4]).astype(np.float32)\nc = np.zeros([1, 4]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c)\nexpect(node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_default_zero_bias\")"
              },
              {
                "summary": "transposeA",
                "code": "node = onnx.helper.make_node(\n    \"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"], transA=1\n)\na = np.random.ranf([6, 3]).astype(np.float32)\nb = np.random.ranf([6, 4]).astype(np.float32)\nc = np.zeros([1, 4]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c, transA=1)\nexpect(node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_transposeA\")"
              },
              {
                "summary": "transposeB",
                "code": "node = onnx.helper.make_node(\n    \"Gemm\", inputs=[\"a\", \"b\", \"c\"], outputs=[\"y\"], transB=1\n)\na = np.random.ranf([3, 6]).astype(np.float32)\nb = np.random.ranf([4, 6]).astype(np.float32)\nc = np.zeros([1, 4]).astype(np.float32)\ny = gemm_reference_implementation(a, b, c, transB=1)\nexpect(node, inputs=[a, b, c], outputs=[y], name=\"test_gemm_transposeB\")"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "graph_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "graph_output_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1000
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "logits",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1000
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        }
      ]
    }
  ]
}