{
  "identifier": "mobilenetv2-12-qdq-static.onnx",
  "format": "ONNX v7",
  "producer": "onnx.quantize 0.1.0",
  "version": "0",
  "functions": [],
  "imports": [
    "ai.onnx v12",
    "ai.onnx.preview.training v1",
    "ai.onnx.training v1",
    "com.ms.internal.nhwc v1",
    "org.pytorch.aten v1",
    "com.microsoft v1",
    "ai.onnx.contrib v1000",
    "com.microsoft.nchwc v1",
    "com.microsoft.experimental v1",
    "ai.onnx.ml v3",
    "com.microsoft.dml v1"
  ],
  "metadata": [],
  "graph": [
    {
      "name": "torch-jit-export",
      "inputs": [
        {
          "name": "input",
          "value": [
            {
              "name": "input",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    1,
                    3,
                    224,
                    224
                  ]
                }
              }
            }
          ]
        }
      ],
      "outputs": [
        {
          "name": "output",
          "value": [
            {
              "name": "output",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    1,
                    1000
                  ]
                }
              }
            }
          ]
        }
      ],
      "nodes": [
        {
          "name": "input_Conv_0_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "input",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        3,
                        224,
                        224
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "input_scale",
                  "initializer": {
                    "name": "input_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "input_zero_point",
                  "initializer": {
                    "name": "input_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "input_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "input_Conv_0_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "input_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "input_scale",
                  "initializer": {
                    "name": "input_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "input_zero_point",
                  "initializer": {
                    "name": "input_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "input_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "475_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "475_quantized",
                  "initializer": {
                    "name": "475_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          32,
                          3,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        32,
                        3,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "475_scale",
                  "initializer": {
                    "name": "475_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "475_zero_point",
                  "initializer": {
                    "name": "475_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "475_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "476_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "476_quantized",
                  "initializer": {
                    "name": "476_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "476_scale",
                  "initializer": {
                    "name": "476_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "476_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_0_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "input_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "475_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "476_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "474_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "474_Conv_0_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "474_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "474_scale",
                  "initializer": {
                    "name": "474_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "474_zero_point",
                  "initializer": {
                    "name": "474_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "474_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "474_Conv_2_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "474_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "474_scale",
                  "initializer": {
                    "name": "474_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "474_zero_point",
                  "initializer": {
                    "name": "474_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "474_Conv_2_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "478_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "478_quantized",
                  "initializer": {
                    "name": "478_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          32,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        32,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "478_scale",
                  "initializer": {
                    "name": "478_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "478_zero_point",
                  "initializer": {
                    "name": "478_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "478_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "479_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "479_quantized",
                  "initializer": {
                    "name": "479_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "479_scale",
                  "initializer": {
                    "name": "479_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "479_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_2_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "474_Conv_2_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "478_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "479_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "477_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "32"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "477_Conv_2_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "477_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "477_zero_point",
                  "initializer": {
                    "name": "477_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "477_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "477_Conv_4_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "477_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "477_zero_point",
                  "initializer": {
                    "name": "477_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "477_Conv_4_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "481_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "481_quantized",
                  "initializer": {
                    "name": "481_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          16,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        16,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "481_scale",
                  "initializer": {
                    "name": "481_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "481_zero_point",
                  "initializer": {
                    "name": "481_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "481_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "482_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "482_quantized",
                  "initializer": {
                    "name": "482_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "482_scale",
                  "initializer": {
                    "name": "482_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "482_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_4_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "477_Conv_4_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "481_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "482_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "480_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "480_Conv_4_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "480_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "480_scale",
                  "initializer": {
                    "name": "480_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "480_zero_point",
                  "initializer": {
                    "name": "480_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "480_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "480_Conv_5_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "480_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "480_scale",
                  "initializer": {
                    "name": "480_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "480_zero_point",
                  "initializer": {
                    "name": "480_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "480_Conv_5_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "484_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "484_quantized",
                  "initializer": {
                    "name": "484_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          96,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        96,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "484_scale",
                  "initializer": {
                    "name": "484_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "484_zero_point",
                  "initializer": {
                    "name": "484_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "484_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "485_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "485_quantized",
                  "initializer": {
                    "name": "485_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "485_scale",
                  "initializer": {
                    "name": "485_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "485_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_5_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "480_Conv_5_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "484_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "485_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "483_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "483_Conv_5_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "483_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "483_zero_point",
                  "initializer": {
                    "name": "483_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "483_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "483_Conv_7_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "483_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "483_zero_point",
                  "initializer": {
                    "name": "483_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "483_Conv_7_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "487_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "487_quantized",
                  "initializer": {
                    "name": "487_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          96,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        96,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "487_scale",
                  "initializer": {
                    "name": "487_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "487_zero_point",
                  "initializer": {
                    "name": "487_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "487_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "488_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "488_quantized",
                  "initializer": {
                    "name": "488_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "488_scale",
                  "initializer": {
                    "name": "488_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "488_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_7_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "483_Conv_7_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "487_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "488_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "486_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "96"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "486_Conv_7_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "486_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "486_zero_point",
                  "initializer": {
                    "name": "486_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "486_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "486_Conv_9_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "486_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "486_zero_point",
                  "initializer": {
                    "name": "486_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "486_Conv_9_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "490_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "490_quantized",
                  "initializer": {
                    "name": "490_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          24,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        24,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "490_scale",
                  "initializer": {
                    "name": "490_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "490_zero_point",
                  "initializer": {
                    "name": "490_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "490_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "491_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "491_quantized",
                  "initializer": {
                    "name": "491_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "491_scale",
                  "initializer": {
                    "name": "491_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "491_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_9_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "486_Conv_9_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "490_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "491_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "489_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "489_Conv_9_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "489_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "489_scale",
                  "initializer": {
                    "name": "489_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "489_zero_point",
                  "initializer": {
                    "name": "489_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "489_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "489_Conv_9_DequantizeLinear/duplicated",
          "description": "Added by EnsureUniqueDQForNodeUnit",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "489_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "489_scale",
                  "initializer": {
                    "name": "489_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "489_zero_point",
                  "initializer": {
                    "name": "489_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "489/duplicated"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "489_Conv_9_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "489_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "489_scale",
                  "initializer": {
                    "name": "489_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "489_zero_point",
                  "initializer": {
                    "name": "489_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "489",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        56,
                        56
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "493_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "493_quantized",
                  "initializer": {
                    "name": "493_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          144,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        144,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "493_scale",
                  "initializer": {
                    "name": "493_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "493_zero_point",
                  "initializer": {
                    "name": "493_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "493_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "494_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "494_quantized",
                  "initializer": {
                    "name": "494_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "494_scale",
                  "initializer": {
                    "name": "494_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "494_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_10_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "489",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        56,
                        56
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "493_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "494_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "492_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "492_Conv_10_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "492_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "492_scale",
                  "initializer": {
                    "name": "492_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "492_zero_point",
                  "initializer": {
                    "name": "492_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "492_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "492_Conv_12_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "492_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "492_scale",
                  "initializer": {
                    "name": "492_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "492_zero_point",
                  "initializer": {
                    "name": "492_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "492_Conv_12_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "496_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "496_quantized",
                  "initializer": {
                    "name": "496_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          144,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        144,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "496_scale",
                  "initializer": {
                    "name": "496_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "496_zero_point",
                  "initializer": {
                    "name": "496_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "496_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "497_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "497_quantized",
                  "initializer": {
                    "name": "497_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "497_scale",
                  "initializer": {
                    "name": "497_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "497_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_12_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "492_Conv_12_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "496_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "497_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "495_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "144"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "495_Conv_12_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "495_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "495_scale",
                  "initializer": {
                    "name": "495_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "495_zero_point",
                  "initializer": {
                    "name": "495_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "495_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "495_Conv_14_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "495_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "495_scale",
                  "initializer": {
                    "name": "495_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "495_zero_point",
                  "initializer": {
                    "name": "495_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "495_Conv_14_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "499_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "499_quantized",
                  "initializer": {
                    "name": "499_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          24,
                          144,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        24,
                        144,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "499_scale",
                  "initializer": {
                    "name": "499_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "499_zero_point",
                  "initializer": {
                    "name": "499_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "499_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "500_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "500_quantized",
                  "initializer": {
                    "name": "500_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "500_scale",
                  "initializer": {
                    "name": "500_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "500_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_14_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "495_Conv_14_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "499_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "500_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "498_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "498_Conv_14_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "498_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "498_scale",
                  "initializer": {
                    "name": "498_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "498_zero_point",
                  "initializer": {
                    "name": "498_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "498_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "498_Conv_14_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "498_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "498_scale",
                  "initializer": {
                    "name": "498_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "498_zero_point",
                  "initializer": {
                    "name": "498_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "498",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        56,
                        56
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_15",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "489/duplicated"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "498",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        56,
                        56
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "339",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        56,
                        56
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "339_Conv_16_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "339",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        56,
                        56
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "339_scale",
                  "initializer": {
                    "name": "339_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "339_zero_point",
                  "initializer": {
                    "name": "339_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "339_Conv_16_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "339_Conv_16_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "339_Conv_16_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "339_scale",
                  "initializer": {
                    "name": "339_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "339_zero_point",
                  "initializer": {
                    "name": "339_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "339_Conv_16_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "502_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "502_quantized",
                  "initializer": {
                    "name": "502_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          144,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        144,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "502_scale",
                  "initializer": {
                    "name": "502_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "502_zero_point",
                  "initializer": {
                    "name": "502_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "502_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "503_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "503_quantized",
                  "initializer": {
                    "name": "503_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "503_scale",
                  "initializer": {
                    "name": "503_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "503_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_16_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "339_Conv_16_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "502_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "503_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "501_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "501_Conv_16_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "501_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "501_scale",
                  "initializer": {
                    "name": "501_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "501_zero_point",
                  "initializer": {
                    "name": "501_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "501_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "501_Conv_18_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "501_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "501_scale",
                  "initializer": {
                    "name": "501_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "501_zero_point",
                  "initializer": {
                    "name": "501_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "501_Conv_18_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "505_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "505_quantized",
                  "initializer": {
                    "name": "505_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          144,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        144,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "505_scale",
                  "initializer": {
                    "name": "505_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "505_zero_point",
                  "initializer": {
                    "name": "505_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "505_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "506_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "506_quantized",
                  "initializer": {
                    "name": "506_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "506_scale",
                  "initializer": {
                    "name": "506_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "506_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_18_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "501_Conv_18_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "505_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "506_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "504_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "144"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "504_Conv_18_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "504_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "504_scale",
                  "initializer": {
                    "name": "504_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "504_zero_point",
                  "initializer": {
                    "name": "504_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "504_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "504_Conv_20_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "504_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "504_scale",
                  "initializer": {
                    "name": "504_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "504_zero_point",
                  "initializer": {
                    "name": "504_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "504_Conv_20_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "508_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "508_quantized",
                  "initializer": {
                    "name": "508_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          32,
                          144,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        32,
                        144,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "508_scale",
                  "initializer": {
                    "name": "508_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "508_zero_point",
                  "initializer": {
                    "name": "508_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "508_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "509_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "509_quantized",
                  "initializer": {
                    "name": "509_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "509_scale",
                  "initializer": {
                    "name": "509_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "509_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_20_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "504_Conv_20_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "508_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "509_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "507_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "507_Conv_20_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "507_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "507_scale",
                  "initializer": {
                    "name": "507_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "507_zero_point",
                  "initializer": {
                    "name": "507_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "507_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "507_Conv_20_DequantizeLinear/duplicated",
          "description": "Added by EnsureUniqueDQForNodeUnit",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "507_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "507_scale",
                  "initializer": {
                    "name": "507_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "507_zero_point",
                  "initializer": {
                    "name": "507_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "507/duplicated"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "507_Conv_20_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "507_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "507_scale",
                  "initializer": {
                    "name": "507_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "507_zero_point",
                  "initializer": {
                    "name": "507_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "507",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "511_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "511_quantized",
                  "initializer": {
                    "name": "511_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          192,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        192,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "511_scale",
                  "initializer": {
                    "name": "511_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "511_zero_point",
                  "initializer": {
                    "name": "511_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "511_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "512_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "512_quantized",
                  "initializer": {
                    "name": "512_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "512_scale",
                  "initializer": {
                    "name": "512_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "512_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_21_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "507",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "511_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "512_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "510_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "510_Conv_21_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "510_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "510_scale",
                  "initializer": {
                    "name": "510_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "510_zero_point",
                  "initializer": {
                    "name": "510_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "510_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "510_Conv_23_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "510_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "510_scale",
                  "initializer": {
                    "name": "510_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "510_zero_point",
                  "initializer": {
                    "name": "510_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "510_Conv_23_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "514_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "514_quantized",
                  "initializer": {
                    "name": "514_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "514_scale",
                  "initializer": {
                    "name": "514_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "514_zero_point",
                  "initializer": {
                    "name": "514_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "514_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "515_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "515_quantized",
                  "initializer": {
                    "name": "515_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "515_scale",
                  "initializer": {
                    "name": "515_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "515_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_23_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "510_Conv_23_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "514_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "515_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "513_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "513_Conv_23_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "513_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "513_scale",
                  "initializer": {
                    "name": "513_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "513_zero_point",
                  "initializer": {
                    "name": "513_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "513_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "513_Conv_25_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "513_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "513_scale",
                  "initializer": {
                    "name": "513_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "513_zero_point",
                  "initializer": {
                    "name": "513_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "513_Conv_25_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "517_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "517_quantized",
                  "initializer": {
                    "name": "517_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          32,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        32,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "517_scale",
                  "initializer": {
                    "name": "517_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "517_zero_point",
                  "initializer": {
                    "name": "517_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "517_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "518_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "518_quantized",
                  "initializer": {
                    "name": "518_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "518_scale",
                  "initializer": {
                    "name": "518_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "518_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_25_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "513_Conv_25_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "517_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "518_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "516_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "516_Conv_25_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "516_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "516_scale",
                  "initializer": {
                    "name": "516_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "516_zero_point",
                  "initializer": {
                    "name": "516_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "516_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "516_Conv_25_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "516_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "516_scale",
                  "initializer": {
                    "name": "516_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "516_zero_point",
                  "initializer": {
                    "name": "516_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "516",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_26",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "507/duplicated"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "516",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "356",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "356_Conv_27_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "356",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "356_scale",
                  "initializer": {
                    "name": "356_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "356_zero_point",
                  "initializer": {
                    "name": "356_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "356_Conv_27_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "356_Conv_27_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "356_Conv_27_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "356_scale",
                  "initializer": {
                    "name": "356_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "356_zero_point",
                  "initializer": {
                    "name": "356_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "356_Conv_27_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "520_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "520_quantized",
                  "initializer": {
                    "name": "520_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          192,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        192,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "520_scale",
                  "initializer": {
                    "name": "520_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "520_zero_point",
                  "initializer": {
                    "name": "520_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "520_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "521_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "521_quantized",
                  "initializer": {
                    "name": "521_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "521_scale",
                  "initializer": {
                    "name": "521_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "521_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_27_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "356_Conv_27_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "520_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "521_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "519_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "519_Conv_27_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "519_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "519_scale",
                  "initializer": {
                    "name": "519_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "519_zero_point",
                  "initializer": {
                    "name": "519_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "519_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "519_Conv_29_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "519_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "519_scale",
                  "initializer": {
                    "name": "519_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "519_zero_point",
                  "initializer": {
                    "name": "519_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "519_Conv_29_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "523_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "523_quantized",
                  "initializer": {
                    "name": "523_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "523_scale",
                  "initializer": {
                    "name": "523_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "523_zero_point",
                  "initializer": {
                    "name": "523_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "523_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "524_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "524_quantized",
                  "initializer": {
                    "name": "524_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "524_scale",
                  "initializer": {
                    "name": "524_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "524_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_29_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "519_Conv_29_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "523_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "524_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "522_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "522_Conv_29_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "522_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "522_scale",
                  "initializer": {
                    "name": "522_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "522_zero_point",
                  "initializer": {
                    "name": "522_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "522_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "522_Conv_31_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "522_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "522_scale",
                  "initializer": {
                    "name": "522_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "522_zero_point",
                  "initializer": {
                    "name": "522_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "522_Conv_31_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "526_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "526_quantized",
                  "initializer": {
                    "name": "526_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          32,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        32,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "526_scale",
                  "initializer": {
                    "name": "526_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "526_zero_point",
                  "initializer": {
                    "name": "526_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "526_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "527_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "527_quantized",
                  "initializer": {
                    "name": "527_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "527_scale",
                  "initializer": {
                    "name": "527_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "527_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_31_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "522_Conv_31_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "526_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "527_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "525_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "525_Conv_31_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "525_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "525_scale",
                  "initializer": {
                    "name": "525_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "525_zero_point",
                  "initializer": {
                    "name": "525_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "525_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "525_Conv_31_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "525_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "525_scale",
                  "initializer": {
                    "name": "525_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "525_zero_point",
                  "initializer": {
                    "name": "525_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "525",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_32",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "356",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "525",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "365",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "365_Conv_33_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "365",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        28,
                        28
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "365_scale",
                  "initializer": {
                    "name": "365_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "365_zero_point",
                  "initializer": {
                    "name": "365_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "365_Conv_33_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "365_Conv_33_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "365_Conv_33_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "365_scale",
                  "initializer": {
                    "name": "365_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "365_zero_point",
                  "initializer": {
                    "name": "365_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "365_Conv_33_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "529_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "529_quantized",
                  "initializer": {
                    "name": "529_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          192,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        192,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "529_scale",
                  "initializer": {
                    "name": "529_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "529_zero_point",
                  "initializer": {
                    "name": "529_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "529_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "530_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "530_quantized",
                  "initializer": {
                    "name": "530_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "530_scale",
                  "initializer": {
                    "name": "530_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "530_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_33_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "365_Conv_33_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "529_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "530_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "528_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "528_Conv_33_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "528_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "528_scale",
                  "initializer": {
                    "name": "528_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "528_zero_point",
                  "initializer": {
                    "name": "528_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "528_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "528_Conv_35_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "528_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "528_scale",
                  "initializer": {
                    "name": "528_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "528_zero_point",
                  "initializer": {
                    "name": "528_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "528_Conv_35_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "532_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "532_quantized",
                  "initializer": {
                    "name": "532_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "532_scale",
                  "initializer": {
                    "name": "532_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "532_zero_point",
                  "initializer": {
                    "name": "532_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "532_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "533_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "533_quantized",
                  "initializer": {
                    "name": "533_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "533_scale",
                  "initializer": {
                    "name": "533_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "533_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_35_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "528_Conv_35_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "532_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "533_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "531_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "531_Conv_35_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "531_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "531_scale",
                  "initializer": {
                    "name": "531_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "531_zero_point",
                  "initializer": {
                    "name": "531_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "531_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "531_Conv_37_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "531_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "531_scale",
                  "initializer": {
                    "name": "531_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "531_zero_point",
                  "initializer": {
                    "name": "531_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "531_Conv_37_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "535_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "535_quantized",
                  "initializer": {
                    "name": "535_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          64,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        64,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "535_scale",
                  "initializer": {
                    "name": "535_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "535_zero_point",
                  "initializer": {
                    "name": "535_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "535_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "536_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "536_quantized",
                  "initializer": {
                    "name": "536_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "536_scale",
                  "initializer": {
                    "name": "536_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "536_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_37_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "531_Conv_37_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "535_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "536_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "534_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "534_Conv_37_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "534_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "534_scale",
                  "initializer": {
                    "name": "534_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "534_zero_point",
                  "initializer": {
                    "name": "534_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "534_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "534_Conv_37_DequantizeLinear/duplicated",
          "description": "Added by EnsureUniqueDQForNodeUnit",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "534_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "534_scale",
                  "initializer": {
                    "name": "534_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "534_zero_point",
                  "initializer": {
                    "name": "534_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "534/duplicated"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "534_Conv_37_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "534_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "534_scale",
                  "initializer": {
                    "name": "534_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "534_zero_point",
                  "initializer": {
                    "name": "534_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "534",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "538_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "538_quantized",
                  "initializer": {
                    "name": "538_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "538_scale",
                  "initializer": {
                    "name": "538_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "538_zero_point",
                  "initializer": {
                    "name": "538_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "538_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "539_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "539_quantized",
                  "initializer": {
                    "name": "539_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "539_scale",
                  "initializer": {
                    "name": "539_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "539_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_38_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "534",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "538_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "539_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "537_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "537_Conv_38_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "537_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "537_scale",
                  "initializer": {
                    "name": "537_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "537_zero_point",
                  "initializer": {
                    "name": "537_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "537_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "537_Conv_40_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "537_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "537_scale",
                  "initializer": {
                    "name": "537_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "537_zero_point",
                  "initializer": {
                    "name": "537_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "537_Conv_40_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "541_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "541_quantized",
                  "initializer": {
                    "name": "541_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "541_scale",
                  "initializer": {
                    "name": "541_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "541_zero_point",
                  "initializer": {
                    "name": "541_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "541_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "542_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "542_quantized",
                  "initializer": {
                    "name": "542_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "542_scale",
                  "initializer": {
                    "name": "542_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "542_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_40_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "537_Conv_40_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "541_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "542_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "540_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "540_Conv_40_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "540_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "540_scale",
                  "initializer": {
                    "name": "540_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "540_zero_point",
                  "initializer": {
                    "name": "540_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "540_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "540_Conv_42_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "540_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "540_scale",
                  "initializer": {
                    "name": "540_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "540_zero_point",
                  "initializer": {
                    "name": "540_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "540_Conv_42_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "544_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "544_quantized",
                  "initializer": {
                    "name": "544_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          64,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        64,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "544_scale",
                  "initializer": {
                    "name": "544_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "544_zero_point",
                  "initializer": {
                    "name": "544_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "544_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "545_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "545_quantized",
                  "initializer": {
                    "name": "545_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "545_scale",
                  "initializer": {
                    "name": "545_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "545_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_42_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "540_Conv_42_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "544_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "545_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "543_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "543_Conv_42_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "543_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "543_scale",
                  "initializer": {
                    "name": "543_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "543_zero_point",
                  "initializer": {
                    "name": "543_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "543_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "543_Conv_42_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "543_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "543_scale",
                  "initializer": {
                    "name": "543_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "543_zero_point",
                  "initializer": {
                    "name": "543_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "543",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_43",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "534/duplicated"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "543",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "382",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "382_Conv_44_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "382",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "382_scale",
                  "initializer": {
                    "name": "382_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "382_zero_point",
                  "initializer": {
                    "name": "382_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "382_Conv_44_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "382_Conv_44_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "382_Conv_44_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "382_scale",
                  "initializer": {
                    "name": "382_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "382_zero_point",
                  "initializer": {
                    "name": "382_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "382_Conv_44_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "547_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "547_quantized",
                  "initializer": {
                    "name": "547_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "547_scale",
                  "initializer": {
                    "name": "547_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "547_zero_point",
                  "initializer": {
                    "name": "547_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "547_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "548_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "548_quantized",
                  "initializer": {
                    "name": "548_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "548_scale",
                  "initializer": {
                    "name": "548_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "548_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_44_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "382_Conv_44_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "547_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "548_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "546_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "546_Conv_44_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "546_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "546_scale",
                  "initializer": {
                    "name": "546_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "546_zero_point",
                  "initializer": {
                    "name": "546_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "546_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "546_Conv_46_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "546_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "546_scale",
                  "initializer": {
                    "name": "546_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "546_zero_point",
                  "initializer": {
                    "name": "546_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "546_Conv_46_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "550_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "550_quantized",
                  "initializer": {
                    "name": "550_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "550_scale",
                  "initializer": {
                    "name": "550_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "550_zero_point",
                  "initializer": {
                    "name": "550_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "550_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "551_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "551_quantized",
                  "initializer": {
                    "name": "551_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "551_scale",
                  "initializer": {
                    "name": "551_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "551_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_46_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "546_Conv_46_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "550_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "551_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "549_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "549_Conv_46_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "549_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "549_scale",
                  "initializer": {
                    "name": "549_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "549_zero_point",
                  "initializer": {
                    "name": "549_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "549_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "549_Conv_48_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "549_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "549_scale",
                  "initializer": {
                    "name": "549_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "549_zero_point",
                  "initializer": {
                    "name": "549_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "549_Conv_48_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "553_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "553_quantized",
                  "initializer": {
                    "name": "553_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          64,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        64,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "553_scale",
                  "initializer": {
                    "name": "553_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "553_zero_point",
                  "initializer": {
                    "name": "553_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "553_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "554_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "554_quantized",
                  "initializer": {
                    "name": "554_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "554_scale",
                  "initializer": {
                    "name": "554_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "554_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_48_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "549_Conv_48_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "553_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "554_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "552_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "552_Conv_48_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "552_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "552_scale",
                  "initializer": {
                    "name": "552_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "552_zero_point",
                  "initializer": {
                    "name": "552_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "552_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "552_Conv_48_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "552_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "552_scale",
                  "initializer": {
                    "name": "552_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "552_zero_point",
                  "initializer": {
                    "name": "552_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "552",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_49",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "382",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "552",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "391",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "391_Conv_50_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "391",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "391_scale",
                  "initializer": {
                    "name": "391_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "391_zero_point",
                  "initializer": {
                    "name": "391_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "391_Conv_50_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "391_Conv_50_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "391_Conv_50_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "391_scale",
                  "initializer": {
                    "name": "391_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "391_zero_point",
                  "initializer": {
                    "name": "391_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "391_Conv_50_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "556_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "556_quantized",
                  "initializer": {
                    "name": "556_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "556_scale",
                  "initializer": {
                    "name": "556_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "556_zero_point",
                  "initializer": {
                    "name": "556_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "556_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "557_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "557_quantized",
                  "initializer": {
                    "name": "557_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "557_scale",
                  "initializer": {
                    "name": "557_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "557_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_50_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "391_Conv_50_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "556_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "557_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "555_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "555_Conv_50_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "555_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "555_scale",
                  "initializer": {
                    "name": "555_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "555_zero_point",
                  "initializer": {
                    "name": "555_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "555_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "555_Conv_52_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "555_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "555_scale",
                  "initializer": {
                    "name": "555_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "555_zero_point",
                  "initializer": {
                    "name": "555_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "555_Conv_52_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "559_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "559_quantized",
                  "initializer": {
                    "name": "559_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "559_scale",
                  "initializer": {
                    "name": "559_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "559_zero_point",
                  "initializer": {
                    "name": "559_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "559_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "560_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "560_quantized",
                  "initializer": {
                    "name": "560_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "560_scale",
                  "initializer": {
                    "name": "560_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "560_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_52_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "555_Conv_52_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "559_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "560_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "558_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "558_Conv_52_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "558_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "558_scale",
                  "initializer": {
                    "name": "558_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "558_zero_point",
                  "initializer": {
                    "name": "558_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "558_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "558_Conv_54_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "558_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "558_scale",
                  "initializer": {
                    "name": "558_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "558_zero_point",
                  "initializer": {
                    "name": "558_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "558_Conv_54_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "562_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "562_quantized",
                  "initializer": {
                    "name": "562_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          64,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        64,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "562_scale",
                  "initializer": {
                    "name": "562_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "562_zero_point",
                  "initializer": {
                    "name": "562_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "562_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "563_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "563_quantized",
                  "initializer": {
                    "name": "563_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "563_scale",
                  "initializer": {
                    "name": "563_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "563_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_54_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "558_Conv_54_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "562_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "563_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "561_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "561_Conv_54_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "561_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "561_scale",
                  "initializer": {
                    "name": "561_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "561_zero_point",
                  "initializer": {
                    "name": "561_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "561_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "561_Conv_54_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "561_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "561_scale",
                  "initializer": {
                    "name": "561_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "561_zero_point",
                  "initializer": {
                    "name": "561_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "561",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_55",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "391",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "561",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "400",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "400_Conv_56_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "400",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        64,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "400_scale",
                  "initializer": {
                    "name": "400_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "400_zero_point",
                  "initializer": {
                    "name": "400_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "400_Conv_56_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "400_Conv_56_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "400_Conv_56_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "400_scale",
                  "initializer": {
                    "name": "400_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "400_zero_point",
                  "initializer": {
                    "name": "400_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "400_Conv_56_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "565_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "565_quantized",
                  "initializer": {
                    "name": "565_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "565_scale",
                  "initializer": {
                    "name": "565_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "565_zero_point",
                  "initializer": {
                    "name": "565_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "565_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "566_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "566_quantized",
                  "initializer": {
                    "name": "566_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "566_scale",
                  "initializer": {
                    "name": "566_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "566_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_56_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "400_Conv_56_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "565_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "566_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "564_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "564_Conv_56_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "564_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "564_scale",
                  "initializer": {
                    "name": "564_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "564_zero_point",
                  "initializer": {
                    "name": "564_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "564_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "564_Conv_58_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "564_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "564_scale",
                  "initializer": {
                    "name": "564_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "564_zero_point",
                  "initializer": {
                    "name": "564_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "564_Conv_58_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "568_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "568_quantized",
                  "initializer": {
                    "name": "568_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "568_scale",
                  "initializer": {
                    "name": "568_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "568_zero_point",
                  "initializer": {
                    "name": "568_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "568_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "569_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "569_quantized",
                  "initializer": {
                    "name": "569_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "569_scale",
                  "initializer": {
                    "name": "569_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "569_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_58_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "564_Conv_58_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "568_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "569_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "567_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "567_Conv_58_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "567_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "567_scale",
                  "initializer": {
                    "name": "567_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "567_zero_point",
                  "initializer": {
                    "name": "567_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "567_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "567_Conv_60_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "567_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "567_scale",
                  "initializer": {
                    "name": "567_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "567_zero_point",
                  "initializer": {
                    "name": "567_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "567_Conv_60_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "571_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "571_quantized",
                  "initializer": {
                    "name": "571_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          96,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        96,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "571_scale",
                  "initializer": {
                    "name": "571_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "571_zero_point",
                  "initializer": {
                    "name": "571_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "571_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "572_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "572_quantized",
                  "initializer": {
                    "name": "572_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "572_scale",
                  "initializer": {
                    "name": "572_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "572_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_60_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "567_Conv_60_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "571_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "572_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "570_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "570_Conv_60_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "570_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "570_scale",
                  "initializer": {
                    "name": "570_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "570_zero_point",
                  "initializer": {
                    "name": "570_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "570_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "570_Conv_60_DequantizeLinear/duplicated",
          "description": "Added by EnsureUniqueDQForNodeUnit",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "570_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "570_scale",
                  "initializer": {
                    "name": "570_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "570_zero_point",
                  "initializer": {
                    "name": "570_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "570/duplicated"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "570_Conv_60_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "570_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "570_scale",
                  "initializer": {
                    "name": "570_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "570_zero_point",
                  "initializer": {
                    "name": "570_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "570",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "574_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "574_quantized",
                  "initializer": {
                    "name": "574_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          576,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        576,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "574_scale",
                  "initializer": {
                    "name": "574_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "574_zero_point",
                  "initializer": {
                    "name": "574_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "574_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "575_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "575_quantized",
                  "initializer": {
                    "name": "575_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "575_scale",
                  "initializer": {
                    "name": "575_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "575_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_61_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "570",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "574_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "575_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "573_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "573_Conv_61_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "573_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "573_scale",
                  "initializer": {
                    "name": "573_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "573_zero_point",
                  "initializer": {
                    "name": "573_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "573_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "573_Conv_63_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "573_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "573_scale",
                  "initializer": {
                    "name": "573_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "573_zero_point",
                  "initializer": {
                    "name": "573_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "573_Conv_63_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "577_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "577_quantized",
                  "initializer": {
                    "name": "577_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          576,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        576,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "577_scale",
                  "initializer": {
                    "name": "577_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "577_zero_point",
                  "initializer": {
                    "name": "577_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "577_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "578_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "578_quantized",
                  "initializer": {
                    "name": "578_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "578_scale",
                  "initializer": {
                    "name": "578_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "578_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_63_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "573_Conv_63_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "577_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "578_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "576_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "576"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "576_Conv_63_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "576_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "576_zero_point",
                  "initializer": {
                    "name": "576_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "576_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "576_Conv_65_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "576_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "576_zero_point",
                  "initializer": {
                    "name": "576_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "576_Conv_65_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "580_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "580_quantized",
                  "initializer": {
                    "name": "580_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          96,
                          576,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        96,
                        576,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "580_scale",
                  "initializer": {
                    "name": "580_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "580_zero_point",
                  "initializer": {
                    "name": "580_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "580_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "581_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "581_quantized",
                  "initializer": {
                    "name": "581_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "581_scale",
                  "initializer": {
                    "name": "581_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "581_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_65_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "576_Conv_65_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "580_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "581_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "579_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "579_Conv_65_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "579_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "579_scale",
                  "initializer": {
                    "name": "579_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "579_zero_point",
                  "initializer": {
                    "name": "579_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "579_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "579_Conv_65_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "579_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "579_scale",
                  "initializer": {
                    "name": "579_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "579_zero_point",
                  "initializer": {
                    "name": "579_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "579",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_66",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "570/duplicated"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "579",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "417",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "417_Conv_67_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "417",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "417_scale",
                  "initializer": {
                    "name": "417_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "417_zero_point",
                  "initializer": {
                    "name": "417_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "417_Conv_67_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "417_Conv_67_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "417_Conv_67_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "417_scale",
                  "initializer": {
                    "name": "417_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "417_zero_point",
                  "initializer": {
                    "name": "417_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "417_Conv_67_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "583_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "583_quantized",
                  "initializer": {
                    "name": "583_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          576,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        576,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "583_scale",
                  "initializer": {
                    "name": "583_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "583_zero_point",
                  "initializer": {
                    "name": "583_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "583_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "584_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "584_quantized",
                  "initializer": {
                    "name": "584_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "584_scale",
                  "initializer": {
                    "name": "584_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "584_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_67_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "417_Conv_67_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "583_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "584_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "582_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "582_Conv_67_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "582_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "582_scale",
                  "initializer": {
                    "name": "582_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "582_zero_point",
                  "initializer": {
                    "name": "582_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "582_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "582_Conv_69_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "582_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "582_scale",
                  "initializer": {
                    "name": "582_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "582_zero_point",
                  "initializer": {
                    "name": "582_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "582_Conv_69_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "586_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "586_quantized",
                  "initializer": {
                    "name": "586_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          576,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        576,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "586_scale",
                  "initializer": {
                    "name": "586_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "586_zero_point",
                  "initializer": {
                    "name": "586_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "586_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "587_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "587_quantized",
                  "initializer": {
                    "name": "587_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "587_scale",
                  "initializer": {
                    "name": "587_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "587_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_69_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "582_Conv_69_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "586_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "587_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "585_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "576"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "585_Conv_69_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "585_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "585_zero_point",
                  "initializer": {
                    "name": "585_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "585_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "585_Conv_71_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "585_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "585_zero_point",
                  "initializer": {
                    "name": "585_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "585_Conv_71_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "589_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "589_quantized",
                  "initializer": {
                    "name": "589_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          96,
                          576,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        96,
                        576,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "589_scale",
                  "initializer": {
                    "name": "589_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "589_zero_point",
                  "initializer": {
                    "name": "589_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "589_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "590_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "590_quantized",
                  "initializer": {
                    "name": "590_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "590_scale",
                  "initializer": {
                    "name": "590_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "590_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_71_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "585_Conv_71_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "589_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "590_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "588_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "588_Conv_71_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "588_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "588_scale",
                  "initializer": {
                    "name": "588_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "588_zero_point",
                  "initializer": {
                    "name": "588_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "588_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "588_Conv_71_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "588_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "588_scale",
                  "initializer": {
                    "name": "588_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "588_zero_point",
                  "initializer": {
                    "name": "588_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "588",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_72",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "417",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "588",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "426",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "426_Conv_73_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "426",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        14,
                        14
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "426_scale",
                  "initializer": {
                    "name": "426_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "426_zero_point",
                  "initializer": {
                    "name": "426_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "426_Conv_73_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "426_Conv_73_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "426_Conv_73_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "426_scale",
                  "initializer": {
                    "name": "426_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "426_zero_point",
                  "initializer": {
                    "name": "426_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "426_Conv_73_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "592_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "592_quantized",
                  "initializer": {
                    "name": "592_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          576,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        576,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "592_scale",
                  "initializer": {
                    "name": "592_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "592_zero_point",
                  "initializer": {
                    "name": "592_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "592_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "593_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "593_quantized",
                  "initializer": {
                    "name": "593_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "593_scale",
                  "initializer": {
                    "name": "593_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "593_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_73_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "426_Conv_73_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "592_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "593_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "591_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "591_Conv_73_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "591_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "591_scale",
                  "initializer": {
                    "name": "591_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "591_zero_point",
                  "initializer": {
                    "name": "591_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "591_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "591_Conv_75_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "591_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "591_scale",
                  "initializer": {
                    "name": "591_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "591_zero_point",
                  "initializer": {
                    "name": "591_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "591_Conv_75_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "595_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "595_quantized",
                  "initializer": {
                    "name": "595_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          576,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        576,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "595_scale",
                  "initializer": {
                    "name": "595_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "595_zero_point",
                  "initializer": {
                    "name": "595_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "595_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "596_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "596_quantized",
                  "initializer": {
                    "name": "596_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "596_scale",
                  "initializer": {
                    "name": "596_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "596_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_75_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "591_Conv_75_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "595_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "596_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "594_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "576"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "594_Conv_75_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "594_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "594_zero_point",
                  "initializer": {
                    "name": "594_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "594_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "594_Conv_77_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "594_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "594_zero_point",
                  "initializer": {
                    "name": "594_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "594_Conv_77_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "598_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "598_quantized",
                  "initializer": {
                    "name": "598_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          160,
                          576,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        160,
                        576,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "598_scale",
                  "initializer": {
                    "name": "598_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "598_zero_point",
                  "initializer": {
                    "name": "598_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "598_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "599_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "599_quantized",
                  "initializer": {
                    "name": "599_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          160
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        160
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "599_scale",
                  "initializer": {
                    "name": "599_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "599_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_77_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "594_Conv_77_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "598_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "599_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "597_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "597_Conv_77_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "597_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "597_scale",
                  "initializer": {
                    "name": "597_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "597_zero_point",
                  "initializer": {
                    "name": "597_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "597_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "597_Conv_77_DequantizeLinear/duplicated",
          "description": "Added by EnsureUniqueDQForNodeUnit",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "597_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "597_scale",
                  "initializer": {
                    "name": "597_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "597_zero_point",
                  "initializer": {
                    "name": "597_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "597/duplicated"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "597_Conv_77_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "597_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "597_scale",
                  "initializer": {
                    "name": "597_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "597_zero_point",
                  "initializer": {
                    "name": "597_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "597",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "601_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "601_quantized",
                  "initializer": {
                    "name": "601_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          960,
                          160,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        960,
                        160,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "601_scale",
                  "initializer": {
                    "name": "601_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "601_zero_point",
                  "initializer": {
                    "name": "601_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "601_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "602_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "602_quantized",
                  "initializer": {
                    "name": "602_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "602_scale",
                  "initializer": {
                    "name": "602_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "602_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_78_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "597",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "601_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "602_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "600_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "600_Conv_78_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "600_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "600_scale",
                  "initializer": {
                    "name": "600_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "600_zero_point",
                  "initializer": {
                    "name": "600_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "600_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "600_Conv_80_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "600_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "600_scale",
                  "initializer": {
                    "name": "600_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "600_zero_point",
                  "initializer": {
                    "name": "600_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "600_Conv_80_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "604_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "604_quantized",
                  "initializer": {
                    "name": "604_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          960,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        960,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "604_scale",
                  "initializer": {
                    "name": "604_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "604_zero_point",
                  "initializer": {
                    "name": "604_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "604_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "605_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "605_quantized",
                  "initializer": {
                    "name": "605_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "605_scale",
                  "initializer": {
                    "name": "605_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "605_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_80_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "600_Conv_80_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "604_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "605_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "603_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "960"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "603_Conv_80_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "603_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "603_scale",
                  "initializer": {
                    "name": "603_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "603_zero_point",
                  "initializer": {
                    "name": "603_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "603_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "603_Conv_82_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "603_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "603_scale",
                  "initializer": {
                    "name": "603_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "603_zero_point",
                  "initializer": {
                    "name": "603_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "603_Conv_82_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "607_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "607_quantized",
                  "initializer": {
                    "name": "607_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          160,
                          960,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        160,
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "607_scale",
                  "initializer": {
                    "name": "607_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "607_zero_point",
                  "initializer": {
                    "name": "607_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "607_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "608_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "608_quantized",
                  "initializer": {
                    "name": "608_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          160
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        160
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "608_scale",
                  "initializer": {
                    "name": "608_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "608_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_82_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "603_Conv_82_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "607_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "608_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "606_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "606_Conv_82_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "606_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "606_scale",
                  "initializer": {
                    "name": "606_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "606_zero_point",
                  "initializer": {
                    "name": "606_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "606_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "606_Conv_82_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "606_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "606_scale",
                  "initializer": {
                    "name": "606_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "606_zero_point",
                  "initializer": {
                    "name": "606_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "606",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_83",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "597/duplicated"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "606",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "443",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "443_Conv_84_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "443",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "443_scale",
                  "initializer": {
                    "name": "443_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "443_zero_point",
                  "initializer": {
                    "name": "443_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "443_Conv_84_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "443_Conv_84_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "443_Conv_84_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "443_scale",
                  "initializer": {
                    "name": "443_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "443_zero_point",
                  "initializer": {
                    "name": "443_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "443_Conv_84_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "610_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "610_quantized",
                  "initializer": {
                    "name": "610_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          960,
                          160,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        960,
                        160,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "610_scale",
                  "initializer": {
                    "name": "610_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "610_zero_point",
                  "initializer": {
                    "name": "610_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "610_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "611_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "611_quantized",
                  "initializer": {
                    "name": "611_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "611_scale",
                  "initializer": {
                    "name": "611_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "611_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_84_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "443_Conv_84_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "610_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "611_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "609_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "609_Conv_84_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "609_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "609_scale",
                  "initializer": {
                    "name": "609_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "609_zero_point",
                  "initializer": {
                    "name": "609_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "609_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "609_Conv_86_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "609_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "609_scale",
                  "initializer": {
                    "name": "609_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "609_zero_point",
                  "initializer": {
                    "name": "609_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "609_Conv_86_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "613_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "613_quantized",
                  "initializer": {
                    "name": "613_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          960,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        960,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "613_scale",
                  "initializer": {
                    "name": "613_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "613_zero_point",
                  "initializer": {
                    "name": "613_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "613_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "614_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "614_quantized",
                  "initializer": {
                    "name": "614_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "614_scale",
                  "initializer": {
                    "name": "614_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "614_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_86_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "609_Conv_86_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "613_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "614_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "612_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "960"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "612_Conv_86_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "612_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "612_zero_point",
                  "initializer": {
                    "name": "612_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "612_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "612_Conv_88_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "612_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "612_zero_point",
                  "initializer": {
                    "name": "612_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "612_Conv_88_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "616_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "616_quantized",
                  "initializer": {
                    "name": "616_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          160,
                          960,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        160,
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "616_scale",
                  "initializer": {
                    "name": "616_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "616_zero_point",
                  "initializer": {
                    "name": "616_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "616_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "617_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "617_quantized",
                  "initializer": {
                    "name": "617_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          160
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        160
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "617_scale",
                  "initializer": {
                    "name": "617_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "617_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_88_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "612_Conv_88_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "616_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "617_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "615_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "615_Conv_88_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "615_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "615_scale",
                  "initializer": {
                    "name": "615_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "615_zero_point",
                  "initializer": {
                    "name": "615_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "615_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "615_Conv_88_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "615_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "615_scale",
                  "initializer": {
                    "name": "615_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "615_zero_point",
                  "initializer": {
                    "name": "615_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "615",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Add_89",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "443",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "615",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "452",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "452_Conv_90_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "452",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        160,
                        7,
                        7
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "452_scale",
                  "initializer": {
                    "name": "452_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "452_zero_point",
                  "initializer": {
                    "name": "452_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "452_Conv_90_QuantizeLinear"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "452_Conv_90_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "452_Conv_90_QuantizeLinear"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "452_scale",
                  "initializer": {
                    "name": "452_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "452_zero_point",
                  "initializer": {
                    "name": "452_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "452_Conv_90_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "619_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "619_quantized",
                  "initializer": {
                    "name": "619_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          960,
                          160,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        960,
                        160,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "619_scale",
                  "initializer": {
                    "name": "619_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "619_zero_point",
                  "initializer": {
                    "name": "619_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "619_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "620_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "620_quantized",
                  "initializer": {
                    "name": "620_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "620_scale",
                  "initializer": {
                    "name": "620_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "620_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_90_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "452_Conv_90_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "619_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "620_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "618_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "618_Conv_90_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "618_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "618_scale",
                  "initializer": {
                    "name": "618_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "618_zero_point",
                  "initializer": {
                    "name": "618_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "618_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "618_Conv_92_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "618_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "618_scale",
                  "initializer": {
                    "name": "618_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "618_zero_point",
                  "initializer": {
                    "name": "618_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "618_Conv_92_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "622_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "622_quantized",
                  "initializer": {
                    "name": "622_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          960,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        960,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "622_scale",
                  "initializer": {
                    "name": "622_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "622_zero_point",
                  "initializer": {
                    "name": "622_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "622_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "623_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "623_quantized",
                  "initializer": {
                    "name": "623_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "623_scale",
                  "initializer": {
                    "name": "623_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "623_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_92_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "618_Conv_92_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "622_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "623_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "621_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "960"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "621_Conv_92_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "621_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "621_scale",
                  "initializer": {
                    "name": "621_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "621_zero_point",
                  "initializer": {
                    "name": "621_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "621_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "621_Conv_94_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "621_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "621_scale",
                  "initializer": {
                    "name": "621_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "621_zero_point",
                  "initializer": {
                    "name": "621_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "621_Conv_94_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "625_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "625_quantized",
                  "initializer": {
                    "name": "625_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          320,
                          960,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        320,
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "625_scale",
                  "initializer": {
                    "name": "625_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "625_zero_point",
                  "initializer": {
                    "name": "625_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "625_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "626_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "626_quantized",
                  "initializer": {
                    "name": "626_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          320
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        320
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "626_scale",
                  "initializer": {
                    "name": "626_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "626_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_94_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "621_Conv_94_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "625_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "626_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "624_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "624_Conv_94_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "624_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "624_scale",
                  "initializer": {
                    "name": "624_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "624_zero_point",
                  "initializer": {
                    "name": "624_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "624_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "624_Conv_95_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "624_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "624_scale",
                  "initializer": {
                    "name": "624_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "624_zero_point",
                  "initializer": {
                    "name": "624_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "624_Conv_95_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "628_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "628_quantized",
                  "initializer": {
                    "name": "628_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          1280,
                          320,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        1280,
                        320,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "628_scale",
                  "initializer": {
                    "name": "628_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "628_zero_point",
                  "initializer": {
                    "name": "628_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "628_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "629_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "629_quantized",
                  "initializer": {
                    "name": "629_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1280
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1280
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "629_scale",
                  "initializer": {
                    "name": "629_scale",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "623_zero_point",
                  "initializer": {
                    "name": "623_zero_point",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int32",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "629_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv_95_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "624_Conv_95_dequantized"
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "628_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "629_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "627_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "auto_pad",
              "type": "string",
              "value": "NOTSET"
            },
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "627_Conv_95_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "627_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "627_zero_point",
                  "initializer": {
                    "name": "627_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "627_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "627_Conv_95_DequantizeLinear/duplicated",
          "description": "Added by EnsureUniqueDQForNodeUnit",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "627_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "576_scale",
                  "initializer": {
                    "name": "576_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "627_zero_point",
                  "initializer": {
                    "name": "627_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "627/duplicated"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "GlobalAveragePool_97",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "627/duplicated"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "464_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "464_GlobalAveragePool_97_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "464_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "464_scale",
                  "initializer": {
                    "name": "464_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "464_zero_point",
                  "initializer": {
                    "name": "464_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "464_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "464_Reshape_103_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "464_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "464_scale",
                  "initializer": {
                    "name": "464_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "464_zero_point",
                  "initializer": {
                    "name": "464_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "464_Reshape_103_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Reshape_103_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "464_Reshape_103_dequantized"
                }
              ]
            },
            {
              "name": "shape",
              "value": [
                {
                  "name": "471",
                  "initializer": {
                    "name": "471",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          2
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        2
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "reshaped",
              "value": [
                {
                  "name": "472_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Reshape",
            "module": "ai.onnx",
            "version": 5,
            "description": "Reshape the input tensor similar to numpy.reshape.\nFirst input is the data tensor, second input is a shape tensor which specifies the output shape. It outputs the reshaped tensor.\nAt most one dimension of the new shape can be -1. In this case, the value is\ninferred from the size of the tensor and the remaining dimensions. A dimension\ncould also be 0, in which case the actual dimension value is unchanged (i.e. taken\nfrom the input tensor). Shape (second input) could be an empty shape, which means converting to a scalar.\nThe input tensor's shape and the output tensor's shape are required to have the same number of elements.",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              },
              {
                "name": "shape",
                "type": "tensor(int64)",
                "description": "Specified shape for output."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "reshaped",
                "type": "T",
                "description": "Reshaped data."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "allowzero",
                "code": "original_shape = [0, 3, 4]\ntest_cases = {\n    \"allowzero_reordered\": np.array([3, 4, 0], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n        allowzero=1,  # if allowzero=1, final shape = (3, 4, 0)\n        # if allowzero=0, final shape = (3, 4, 4)\n    )\n\n    reshaped = reshape_reference_implementation(data, shape, allowzero=1)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              },
              {
                "summary": "reshape",
                "code": "original_shape = [2, 3, 4]\ntest_cases = {\n    \"reordered_all_dims\": np.array([4, 2, 3], dtype=np.int64),\n    \"reordered_last_dims\": np.array([2, 4, 3], dtype=np.int64),\n    \"reduced_dims\": np.array([2, 12], dtype=np.int64),\n    \"extended_dims\": np.array([2, 3, 2, 2], dtype=np.int64),\n    \"one_dim\": np.array([24], dtype=np.int64),\n    \"negative_dim\": np.array([2, -1, 2], dtype=np.int64),\n    \"negative_extended_dims\": np.array([-1, 2, 3, 4], dtype=np.int64),\n    \"zero_dim\": np.array([2, 0, 4, 1], dtype=np.int64),\n    \"zero_and_negative_dim\": np.array([2, 0, 1, -1], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n    )\n\n    reshaped = reshape_reference_implementation(data, shape)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              }
            ],
            "category": "Shape"
          }
        },
        {
          "name": "472_Reshape_103_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "472_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "464_scale",
                  "initializer": {
                    "name": "464_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "464_zero_point",
                  "initializer": {
                    "name": "464_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "472_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "472_Gemm_104_MatMul_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "472_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "464_scale",
                  "initializer": {
                    "name": "464_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "464_zero_point",
                  "initializer": {
                    "name": "464_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "472_Gemm_104_MatMul_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "classifier.1.weight_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "classifier.1.weight_quantized",
                  "initializer": {
                    "name": "classifier.1.weight_quantized",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": [
                          1280,
                          1000
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": [
                        1280,
                        1000
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "classifier.1.weight_scale",
                  "initializer": {
                    "name": "classifier.1.weight_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "classifier.1.weight_zero_point",
                  "initializer": {
                    "name": "classifier.1.weight_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "int8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "classifier.1.weight_dequantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Gemm_104_MatMul_quant",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "472_Gemm_104_MatMul_dequantized"
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "classifier.1.weight_dequantized"
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "output_MatMul_QuantizeInput"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "MatMul",
            "module": "ai.onnx",
            "version": 9,
            "description": "Matrix product that behaves like [numpy.matmul](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "N-dimensional matrix A"
              },
              {
                "name": "B",
                "type": "T",
                "description": "N-dimensional matrix B"
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Matrix multiply results from A * B"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float/int tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "matmul",
                "code": "node = onnx.helper.make_node(\n    \"MatMul\",\n    inputs=[\"a\", \"b\"],\n    outputs=[\"c\"],\n)\n\n# 2d\na = np.random.randn(3, 4).astype(np.float32)\nb = np.random.randn(4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_2d\")\n\n# 3d\na = np.random.randn(2, 3, 4).astype(np.float32)\nb = np.random.randn(2, 4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_3d\")\n\n# 4d\na = np.random.randn(1, 2, 3, 4).astype(np.float32)\nb = np.random.randn(1, 2, 4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_4d\")"
              }
            ]
          }
        },
        {
          "name": "output_MatMul_Gemm_104_MatMul_QuantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "output_MatMul_QuantizeInput"
                }
              ]
            },
            {
              "name": "y_scale",
              "value": [
                {
                  "name": "output_MatMul_scale",
                  "initializer": {
                    "name": "output_MatMul_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "y_zero_point",
              "value": [
                {
                  "name": "output_MatMul_zero_point",
                  "initializer": {
                    "name": "output_MatMul_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "output_MatMul_quantized"
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "QuantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.\nThe quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.\nFor (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.\n",
            "inputs": [
              {
                "name": "x",
                "type": "T1",
                "description": "N-D full precision Input tensor to be quantized."
              },
              {
                "name": "y_scale",
                "type": "tensor(float)",
                "description": "Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "y_zero_point",
                "type": "T2",
                "option": "optional",
                "description": "Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "T2",
                "description": "N-D quantized output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x' to float or int32 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)"
                ]
              },
              {
                "description": "Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        [\n            [[-162, 10], [-100, 232], [-20, -50]],\n            [[-76, 0], [0, 252], [32, -44]],\n            [[245, -485], [-960, -270], [-375, -470]],\n        ],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array([2, 4, 5], dtype=np.float32)\ny_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (x / y_scale.reshape(1, 3, 1, 1) + y_zero_point.reshape(1, 3, 1, 1)).astype(\n    np.uint8\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [6.0, 12.0, 50.0, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\ny_zero_point = np.array(\n    [\n        [0, 1],\n        [1, 0],\n        [2, 3],\n    ],\n    dtype=np.uint8,\n)\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\nassert y_scale.shape == y_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\ny_zero_point_elementwise = np.repeat(\n    y_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = np.rint(x / y_scale_elementwise + y_zero_point_elementwise).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_asymmetric\",\n)"
              },
              {
                "summary": "blocked_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n    output_dtype=TensorProto.INT16,\n)\n\nx = np.array(\n    [\n        [6.0, -8, -10, 5.0],\n        [1.0, 8.0, 4.0, 5.0],\n        [0.0, 20.0, 10.0, 4.0],\n    ],\n    dtype=np.float32,\n)\n\ny_scale = np.array(\n    [\n        [1.5, 2.5],\n        [3.0, 4.9],\n        [5.1, 6.9],\n    ],\n    dtype=np.float32,\n)\n\n# x.shape = (3, 4)\n# y_scale.shape = (3, 2)\n\nblock_axis = 1\n# The block shape is [x.shape[i] // y_scale.shape[i] for i in range(len(x.shape))] = (1, 2)\nassert all(\n    x.shape[i] == y_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % y_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // y_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\ny_scale_elementwise = np.repeat(y_scale, repeats=repeats, axis=block_axis)\n\ny_val = np.clip(\n    np.rint(x / y_scale_elementwise), a_min=-32768, a_max=32767\n).astype(np.int16)\ny = make_tensor(\n    \"y\",\n    TensorProto.INT16,\n    x.shape,\n    y_val,\n)\nexpect(\n    node,\n    inputs=[x, y_scale],\n    outputs=[y],\n    name=\"test_quantizelinear_blocked_symmetric\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0.0, 1.0, 2.0, 100000.0, 200.0]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = make_tensor(\"y_zero_point\", TensorProto.FLOAT8E5M2, [1], [0.0])\ny = make_tensor(\"y\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, 96])\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [-0.0, -2.5, -4.8, -8.6],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\",\n    TensorProto.FLOAT4E2M1,\n    y_scale.shape,\n    np.zeros_like(y_scale),\n)\ny = make_tensor(\n    \"y\",\n    TensorProto.FLOAT4E2M1,\n    x.shape,\n    [0, 1, 2, 4, -6, -6, 2, 3, 0, -0.5, -1, -2],\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -514.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65022.0,\n        -66046.0,\n        65023.0,\n        -66047.0,\n        65024.0,\n        -66048.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.int16(256)\ny = np.array(\n    [\n        256,\n        -1,\n        258,\n        254,\n        257,\n        255,\n        258,\n        254,\n        32767,\n        -32767,\n        32767,\n        -32768,\n        32767,\n        -32768,\n        32767,\n        -32768,\n    ]\n).astype(np.int16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.INT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.INT4, x.shape, [1, 2, 3, 5, -8, -6, 3, 4, 4, 5, 5, 7]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_int4\",\n)"
              },
              {
                "summary": "quantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([0, 2, 3, 1000, -254, -1000]).astype(np.float32)\ny_scale = np.float32(2)\ny_zero_point = np.uint8(128)\ny = np.array([128, 129, 130, 255, 1, 0]).astype(np.uint8)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array(\n    [\n        0.0,\n        -128.0,\n        3.0,\n        -3.0,\n        2.9,\n        -2.9,\n        3.1,\n        -3.1,\n        65536.0,\n        -65534.0,\n        70000.0,\n        -70000.0,\n    ]\n).astype(np.float32)\ny_scale = np.float32(2.0)\ny_zero_point = np.uint16(32767)\ny = np.array(\n    [\n        32767,\n        32703,\n        32769,\n        32765,\n        32768,\n        32766,\n        32769,\n        32765,\n        65535,\n        0,\n        65535,\n        0,\n    ]\n).astype(np.uint16)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"QuantizeLinear\",\n    inputs=[\"x\", \"y_scale\", \"y_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\nx = np.array(\n    [\n        [0.0, 2.5, 4.8, 8.6],\n        [-30, -20, 6, 9],\n        [12, 15, 16, 40],\n    ]\n).astype(np.float32)\n\ny_scale = np.asarray([2.0, 3.0, 4.0], dtype=np.float32)\ny_zero_point = make_tensor(\n    \"y_zero_point\", TensorProto.UINT4, y_scale.shape, np.ones_like(y_scale)\n)\ny = make_tensor(\n    \"y\", TensorProto.UINT4, x.shape, [1, 2, 3, 5, -1, -1, 3, 4, 4, 5, 5, 11]\n)\n\nexpect(\n    node,\n    inputs=[x, y_scale, y_zero_point],\n    outputs=[y],\n    name=\"test_quantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "output_MatMul_Gemm_104_MatMul_DequantizeLinear",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "x",
              "value": [
                {
                  "name": "output_MatMul_quantized"
                }
              ]
            },
            {
              "name": "x_scale",
              "value": [
                {
                  "name": "output_MatMul_scale",
                  "initializer": {
                    "name": "output_MatMul_scale",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "x_zero_point",
              "value": [
                {
                  "name": "output_MatMul_zero_point",
                  "initializer": {
                    "name": "output_MatMul_zero_point",
                    "category": "Initializer",
                    "encoding": "|",
                    "type": {
                      "dataType": "uint8",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "uint8",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "y",
              "value": [
                {
                  "name": "output_MatMul",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1000
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "DequantizeLinear",
            "module": "ai.onnx",
            "version": 10,
            "description": "The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.\nThe dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.\n'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,\nthere's no zero point (zero point is supposed to be 0).\n",
            "inputs": [
              {
                "name": "x",
                "type": "T",
                "description": "N-D quantized input tensor to be de-quantized."
              },
              {
                "name": "x_scale",
                "type": "tensor(float)",
                "description": "Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization."
              },
              {
                "name": "x_zero_point",
                "type": "T",
                "option": "optional",
                "description": "Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "y",
                "type": "tensor(float)",
                "description": "N-D full precision output tensor. It has same shape as input 'x'."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(int8)",
                  "tensor(uint8)",
                  "tensor(int32)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "axis",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# 1-D tensor zero point and scale of size equal to axis 1 of the input tensor\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\nx_scale = np.array([2, 4, 5], dtype=np.float32)\nx_zero_point = np.array([84, 24, 196], dtype=np.uint8)\ny = (\n    x.astype(np.float32) - x_zero_point.reshape(1, 3, 1, 1).astype(np.float32)\n) * x_scale.reshape(1, 3, 1, 1)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_axis\",\n)"
              },
              {
                "summary": "blocked",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=1,\n    block_size=2,\n)\n\nx = np.array(\n    [\n        [\n            [[3, 89], [34, 200], [74, 59]],\n            [[5, 24], [24, 87], [32, 13]],\n            [[5, 12], [12, 33], [65, 42]],\n            [[245, 99], [4, 142], [121, 102]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\nx_scale = np.array(\n    [\n        [\n            [[3.0, 2.0], [4.0, 1.0], [2.0, 2.0]],\n            [[5.0, 2.0], [4.0, 3.0], [5.0, 2.0]],\n        ],\n    ],\n    dtype=np.float32,\n)\nx_zero_point = np.array(\n    [\n        [\n            [[1, 0], [0, 1], [2, 20]],\n            [[3, 2], [4, 3], [15, 2]],\n        ],\n    ],\n    dtype=np.uint8,\n)\n\n# x.shape = (1, 4, 3, 2)\n# x_scale.shape = (1, 2, 3, 2)\nassert x_scale.shape == x_zero_point.shape\nblock_axis = 1\n# The block shape is [x.shape[i] // x_scale.shape[i] for i in range(len(x.shape))] = (1, 2, 1, 1)\nassert all(\n    x.shape[i] == x_scale.shape[i]\n    for i in range(len(x.shape))\n    if i != block_axis\n)\nassert x.shape[block_axis] % x_scale.shape[block_axis] == 0\nrepeats = x.shape[block_axis] // x_scale.shape[block_axis]\n\n# Create element-wise scale and zero point\nx_scale_elementwise = np.repeat(x_scale, repeats=repeats, axis=block_axis)\nx_zero_point_elementwise = np.repeat(\n    x_zero_point, repeats=repeats, axis=block_axis\n)\n\ny = (\n    x.astype(np.float32) - x_zero_point_elementwise.astype(np.float32)\n) * x_scale_elementwise\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_blocked\",\n)"
              },
              {
                "summary": "dequantizelinear",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\n# scalar zero point and scale\nx = np.array([0, 3, 128, 255]).astype(np.uint8)\nx_scale = np.float32(2)\nx_zero_point = np.uint8(128)\ny = np.array([-256, -250, 0, 254], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear\",\n)"
              },
              {
                "summary": "e4m3fn",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn\",\n)"
              },
              {
                "summary": "e4m3fn_float16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nx_scale = np.float16(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float16)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_float16\",\n)"
              },
              {
                "summary": "e4m3fn_zero_point",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E4M3FN, [5], [0, 0.5, 1, 448, -104])\nzero_point = make_tensor(\"zero_point\", TensorProto.FLOAT8E4M3FN, [1], [0])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 896.0, -208.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_e4m3fn_zero_point\",\n)"
              },
              {
                "summary": "e5m2",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT8E5M2, [5], [0, 0.5, 1, 49152, -96])\nx_scale = np.float32(2)\ny = np.array([0.0, 1.0, 2.0, 98304.0, -192.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale],\n    outputs=[y],\n    name=\"test_dequantizelinear_e5m2\",\n)"
              },
              {
                "summary": "float4e2m1",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.FLOAT4E2M1, [5], [0, 1, -1, 1.5, -4])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.FLOAT4E2M1, (1,), [0])\ny = np.array([0, 2, -2, 3, -8], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_float4e2m1\",\n)"
              },
              {
                "summary": "int16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-300, -30, -1025, 1270]).astype(np.int16)\nx_scale = np.float32(2)\nx_zero_point = np.int16(-1024)\ny = np.array([1448.0, 1988.0, -2.0, 4588.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int16\",\n)"
              },
              {
                "summary": "int4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.INT4, [5], [0, 1, 7, -4, -8])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.INT4, (1,), [1])\ny = np.array([-2, 0, 12, -10, -18], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_int4\",\n)"
              },
              {
                "summary": "uint16",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([30000, 31000, 32768, 33000]).astype(np.uint16)\nx_scale = np.float32(2)\nx_zero_point = np.uint16(32767)\ny = np.array([-5534.0, -3534.0, 2.0, 466.0], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint16\",\n)"
              },
              {
                "summary": "uint4",
                "code": "node = onnx.helper.make_node(\n    \"DequantizeLinear\",\n    inputs=[\"x\", \"x_scale\", \"x_zero_point\"],\n    outputs=[\"y\"],\n    axis=0,\n)\n\n# scalar zero point and scale\nx = make_tensor(\"x\", TensorProto.UINT4, [5], [0, 1, 7, 10, 15])\nx_scale = np.float32(2)\nx_zero_point = make_tensor(\"x_zero_point\", TensorProto.UINT4, (1,), [1])\ny = np.array([-2, 0, 12, 18, 28], dtype=np.float32)\n\nexpect(\n    node,\n    inputs=[x, x_scale, x_zero_point],\n    outputs=[y],\n    name=\"test_dequantizelinear_uint4\",\n)"
              }
            ]
          }
        },
        {
          "name": "Gemm_104_Add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "output_MatMul",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1000
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "classifier.1.bias",
                  "initializer": {
                    "name": "classifier.1.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1000
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1000
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "output",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1000
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        }
      ]
    }
  ]
}