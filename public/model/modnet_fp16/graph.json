{
  "identifier": "modnet_fp16.onnx",
  "format": "ONNX v6",
  "producer": "pytorch 1.7",
  "version": "0",
  "functions": [],
  "imports": [
    "ai.onnx v11"
  ],
  "metadata": [],
  "graph": [
    {
      "name": "torch-jit-export",
      "inputs": [
        {
          "name": "input",
          "value": [
            {
              "name": "input",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    "batch_size",
                    3,
                    "height",
                    "width"
                  ]
                }
              }
            }
          ]
        }
      ],
      "outputs": [
        {
          "name": "output",
          "value": [
            {
              "name": "output",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    "batch_size",
                    1,
                    "height",
                    "width"
                  ]
                }
              }
            }
          ]
        }
      ],
      "nodes": [
        {
          "name": "graph_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "input",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "graph_input_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Conv_0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "graph_input_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1013",
                  "initializer": {
                    "name": "1013",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          3,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        3,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1014",
                  "initializer": {
                    "name": "1014",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1012",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__0",
                        "unk__1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1012",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__0",
                        "unk__1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "442",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "443",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "444",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__0",
                        "unk__1"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "444",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__0",
                        "unk__1"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1016",
                  "initializer": {
                    "name": "1016",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1017",
                  "initializer": {
                    "name": "1017",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1015",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__2",
                        "unk__3"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "32"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1015",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__2",
                        "unk__3"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "447",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "448",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "449",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__2",
                        "unk__3"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "449",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__2",
                        "unk__3"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1019",
                  "initializer": {
                    "name": "1019",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1020",
                  "initializer": {
                    "name": "1020",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1018",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__4",
                        "unk__5"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1018",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__4",
                        "unk__5"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1022",
                  "initializer": {
                    "name": "1022",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1023",
                  "initializer": {
                    "name": "1023",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1021",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__6",
                        "unk__7"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_12",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1021",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__6",
                        "unk__7"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "454",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "455",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "456",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__6",
                        "unk__7"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_13",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "456",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__6",
                        "unk__7"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1025",
                  "initializer": {
                    "name": "1025",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1026",
                  "initializer": {
                    "name": "1026",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1024",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__8",
                        "unk__9"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "96"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_16",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1024",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__8",
                        "unk__9"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "459",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "460",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "461",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__8",
                        "unk__9"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_17",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "461",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__8",
                        "unk__9"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1028",
                  "initializer": {
                    "name": "1028",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          24,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        24,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1029",
                  "initializer": {
                    "name": "1029",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1027",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__10",
                        "unk__11"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv_18",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1027",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__10",
                        "unk__11"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1031",
                  "initializer": {
                    "name": "1031",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1032",
                  "initializer": {
                    "name": "1032",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1030",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__12",
                        "unk__13"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_21",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1030",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__12",
                        "unk__13"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "466",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "467",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "468",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__12",
                        "unk__13"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_22",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "468",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__12",
                        "unk__13"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1034",
                  "initializer": {
                    "name": "1034",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1035",
                  "initializer": {
                    "name": "1035",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1033",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__14",
                        "unk__15"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "144"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_25",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1033",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__14",
                        "unk__15"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "471",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "472",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "473",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__14",
                        "unk__15"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_26",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "473",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__14",
                        "unk__15"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1037",
                  "initializer": {
                    "name": "1037",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          24,
                          144,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        24,
                        144,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1038",
                  "initializer": {
                    "name": "1038",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1036",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__16",
                        "unk__17"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_27",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "1027",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__10",
                        "unk__11"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1036",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__16",
                        "unk__17"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "476",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__18",
                        "unk__19"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_28",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "476",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__18",
                        "unk__19"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1040",
                  "initializer": {
                    "name": "1040",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1041",
                  "initializer": {
                    "name": "1041",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1039",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__20",
                        "unk__21"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_31",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1039",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__20",
                        "unk__21"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "479",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "480",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "481",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__20",
                        "unk__21"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_32",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "481",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__20",
                        "unk__21"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1043",
                  "initializer": {
                    "name": "1043",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1044",
                  "initializer": {
                    "name": "1044",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          144
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        144
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1042",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__22",
                        "unk__23"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "144"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_35",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1042",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__22",
                        "unk__23"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "484",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "485",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "486",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__22",
                        "unk__23"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_36",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "486",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        144,
                        "unk__22",
                        "unk__23"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1046",
                  "initializer": {
                    "name": "1046",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          144,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        144,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1047",
                  "initializer": {
                    "name": "1047",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1045",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__24",
                        "unk__25"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv_37",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1045",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__24",
                        "unk__25"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1049",
                  "initializer": {
                    "name": "1049",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1050",
                  "initializer": {
                    "name": "1050",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1048",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__26",
                        "unk__27"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_40",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1048",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__26",
                        "unk__27"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "491",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "492",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "493",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__26",
                        "unk__27"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_41",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "493",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__26",
                        "unk__27"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1052",
                  "initializer": {
                    "name": "1052",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1053",
                  "initializer": {
                    "name": "1053",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1051",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__28",
                        "unk__29"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_44",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1051",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__28",
                        "unk__29"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "496",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "497",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "498",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__28",
                        "unk__29"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_45",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "498",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__28",
                        "unk__29"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1055",
                  "initializer": {
                    "name": "1055",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1056",
                  "initializer": {
                    "name": "1056",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1054",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__30",
                        "unk__31"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_46",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "1045",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__24",
                        "unk__25"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1054",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__30",
                        "unk__31"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "501",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__32",
                        "unk__33"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_47",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "501",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__32",
                        "unk__33"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1058",
                  "initializer": {
                    "name": "1058",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1059",
                  "initializer": {
                    "name": "1059",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1057",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__34",
                        "unk__35"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_50",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1057",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__34",
                        "unk__35"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "504",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "505",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "506",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__34",
                        "unk__35"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_51",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "506",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__34",
                        "unk__35"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1061",
                  "initializer": {
                    "name": "1061",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1062",
                  "initializer": {
                    "name": "1062",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1060",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__36",
                        "unk__37"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_54",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1060",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__36",
                        "unk__37"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "509",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "510",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "511",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__36",
                        "unk__37"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_55",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "511",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__36",
                        "unk__37"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1064",
                  "initializer": {
                    "name": "1064",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1065",
                  "initializer": {
                    "name": "1065",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1063",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__38",
                        "unk__39"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_56",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "501",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__32",
                        "unk__33"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1063",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__38",
                        "unk__39"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "514",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__40",
                        "unk__41"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_57",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "514",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__40",
                        "unk__41"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1067",
                  "initializer": {
                    "name": "1067",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1068",
                  "initializer": {
                    "name": "1068",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1066",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__42",
                        "unk__43"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_60",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1066",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__42",
                        "unk__43"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "517",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "518",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "519",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__42",
                        "unk__43"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_61",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "519",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__42",
                        "unk__43"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1070",
                  "initializer": {
                    "name": "1070",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1071",
                  "initializer": {
                    "name": "1071",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          192
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        192
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1069",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__44",
                        "unk__45"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "192"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_64",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1069",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__44",
                        "unk__45"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "522",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "523",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "524",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__44",
                        "unk__45"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_65",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "524",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        192,
                        "unk__44",
                        "unk__45"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1073",
                  "initializer": {
                    "name": "1073",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          192,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        192,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1074",
                  "initializer": {
                    "name": "1074",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1072",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__46",
                        "unk__47"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv_66",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1072",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__46",
                        "unk__47"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1076",
                  "initializer": {
                    "name": "1076",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1077",
                  "initializer": {
                    "name": "1077",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1075",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__48",
                        "unk__49"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_69",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1075",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__48",
                        "unk__49"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "529",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "530",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "531",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__48",
                        "unk__49"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_70",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "531",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__48",
                        "unk__49"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1079",
                  "initializer": {
                    "name": "1079",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1080",
                  "initializer": {
                    "name": "1080",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1078",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__50",
                        "unk__51"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_73",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1078",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__50",
                        "unk__51"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "534",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "535",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "536",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__50",
                        "unk__51"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_74",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "536",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__50",
                        "unk__51"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1082",
                  "initializer": {
                    "name": "1082",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1083",
                  "initializer": {
                    "name": "1083",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1081",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__52",
                        "unk__53"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_75",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "1072",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__46",
                        "unk__47"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1081",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__52",
                        "unk__53"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "539",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__54",
                        "unk__55"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_76",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "539",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__54",
                        "unk__55"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1085",
                  "initializer": {
                    "name": "1085",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1086",
                  "initializer": {
                    "name": "1086",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1084",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__56",
                        "unk__57"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_79",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1084",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__56",
                        "unk__57"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "542",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "543",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "544",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__56",
                        "unk__57"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_80",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "544",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__56",
                        "unk__57"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1088",
                  "initializer": {
                    "name": "1088",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1089",
                  "initializer": {
                    "name": "1089",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1087",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__58",
                        "unk__59"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_83",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1087",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__58",
                        "unk__59"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "547",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "548",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "549",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__58",
                        "unk__59"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_84",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "549",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__58",
                        "unk__59"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1091",
                  "initializer": {
                    "name": "1091",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1092",
                  "initializer": {
                    "name": "1092",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1090",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__60",
                        "unk__61"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_85",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "539",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__54",
                        "unk__55"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1090",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__60",
                        "unk__61"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "552",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__62",
                        "unk__63"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_86",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "552",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__62",
                        "unk__63"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1094",
                  "initializer": {
                    "name": "1094",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1095",
                  "initializer": {
                    "name": "1095",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1093",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__64",
                        "unk__65"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_89",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1093",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__64",
                        "unk__65"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "555",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "556",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "557",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__64",
                        "unk__65"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_90",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "557",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__64",
                        "unk__65"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1097",
                  "initializer": {
                    "name": "1097",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1098",
                  "initializer": {
                    "name": "1098",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1096",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__66",
                        "unk__67"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_93",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1096",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__66",
                        "unk__67"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "560",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "561",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "562",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__66",
                        "unk__67"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_94",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "562",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__66",
                        "unk__67"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1100",
                  "initializer": {
                    "name": "1100",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1101",
                  "initializer": {
                    "name": "1101",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1099",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__68",
                        "unk__69"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_95",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "552",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__62",
                        "unk__63"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1099",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__68",
                        "unk__69"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "565",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__70",
                        "unk__71"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_96",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "565",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        64,
                        "unk__70",
                        "unk__71"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1103",
                  "initializer": {
                    "name": "1103",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          64,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        64,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1104",
                  "initializer": {
                    "name": "1104",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1102",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__72",
                        "unk__73"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_99",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1102",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__72",
                        "unk__73"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "568",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "569",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "570",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__72",
                        "unk__73"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_100",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "570",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__72",
                        "unk__73"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1106",
                  "initializer": {
                    "name": "1106",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1107",
                  "initializer": {
                    "name": "1107",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          384
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        384
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1105",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__74",
                        "unk__75"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "384"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_103",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1105",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__74",
                        "unk__75"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "573",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "574",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "575",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__74",
                        "unk__75"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_104",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "575",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        384,
                        "unk__74",
                        "unk__75"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1109",
                  "initializer": {
                    "name": "1109",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          384,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        384,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1110",
                  "initializer": {
                    "name": "1110",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1108",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__76",
                        "unk__77"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv_105",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1108",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__76",
                        "unk__77"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1112",
                  "initializer": {
                    "name": "1112",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1113",
                  "initializer": {
                    "name": "1113",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1111",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__78",
                        "unk__79"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_108",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1111",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__78",
                        "unk__79"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "580",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "581",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "582",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__78",
                        "unk__79"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_109",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "582",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__78",
                        "unk__79"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1115",
                  "initializer": {
                    "name": "1115",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1116",
                  "initializer": {
                    "name": "1116",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1114",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__80",
                        "unk__81"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "576"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_112",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1114",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__80",
                        "unk__81"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "585",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "586",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "587",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__80",
                        "unk__81"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_113",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "587",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__80",
                        "unk__81"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1118",
                  "initializer": {
                    "name": "1118",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          576,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        576,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1119",
                  "initializer": {
                    "name": "1119",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1117",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__82",
                        "unk__83"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_114",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "1108",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__76",
                        "unk__77"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1117",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__82",
                        "unk__83"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "590",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__84",
                        "unk__85"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_115",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "590",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__84",
                        "unk__85"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1121",
                  "initializer": {
                    "name": "1121",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1122",
                  "initializer": {
                    "name": "1122",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1120",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__86",
                        "unk__87"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_118",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1120",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__86",
                        "unk__87"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "593",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "594",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "595",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__86",
                        "unk__87"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_119",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "595",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__86",
                        "unk__87"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1124",
                  "initializer": {
                    "name": "1124",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1125",
                  "initializer": {
                    "name": "1125",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1123",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__88",
                        "unk__89"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "576"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_122",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1123",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__88",
                        "unk__89"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "598",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "599",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "600",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__88",
                        "unk__89"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_123",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "600",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__88",
                        "unk__89"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1127",
                  "initializer": {
                    "name": "1127",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          576,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        576,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1128",
                  "initializer": {
                    "name": "1128",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1126",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__90",
                        "unk__91"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_124",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "590",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__84",
                        "unk__85"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1126",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__90",
                        "unk__91"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "603",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__92",
                        "unk__93"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_125",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "603",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        96,
                        "unk__92",
                        "unk__93"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1130",
                  "initializer": {
                    "name": "1130",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1131",
                  "initializer": {
                    "name": "1131",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1129",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__94",
                        "unk__95"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_128",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1129",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__94",
                        "unk__95"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "606",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "607",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "608",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__94",
                        "unk__95"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_129",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "608",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__94",
                        "unk__95"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1133",
                  "initializer": {
                    "name": "1133",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1134",
                  "initializer": {
                    "name": "1134",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          576
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        576
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1132",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__96",
                        "unk__97"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "576"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_132",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1132",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__96",
                        "unk__97"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "611",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "612",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "613",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__96",
                        "unk__97"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_133",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "613",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        576,
                        "unk__96",
                        "unk__97"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1136",
                  "initializer": {
                    "name": "1136",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          160,
                          576,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        160,
                        576,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1137",
                  "initializer": {
                    "name": "1137",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          160
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        160
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1135",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__98",
                        "unk__99"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv_134",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1135",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__98",
                        "unk__99"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1139",
                  "initializer": {
                    "name": "1139",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960,
                          160,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960,
                        160,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1140",
                  "initializer": {
                    "name": "1140",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1138",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__100",
                        "unk__101"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_137",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1138",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__100",
                        "unk__101"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "618",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "619",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "620",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__100",
                        "unk__101"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_138",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "620",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__100",
                        "unk__101"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1142",
                  "initializer": {
                    "name": "1142",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1143",
                  "initializer": {
                    "name": "1143",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1141",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__102",
                        "unk__103"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "960"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_141",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1141",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__102",
                        "unk__103"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "623",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "624",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "625",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__102",
                        "unk__103"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_142",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "625",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__102",
                        "unk__103"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1145",
                  "initializer": {
                    "name": "1145",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          160,
                          960,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        160,
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1146",
                  "initializer": {
                    "name": "1146",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          160
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        160
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1144",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__104",
                        "unk__105"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_143",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "1135",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__98",
                        "unk__99"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1144",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__104",
                        "unk__105"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "628",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__106",
                        "unk__107"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_144",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "628",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__106",
                        "unk__107"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1148",
                  "initializer": {
                    "name": "1148",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960,
                          160,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960,
                        160,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1149",
                  "initializer": {
                    "name": "1149",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1147",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__108",
                        "unk__109"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_147",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1147",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__108",
                        "unk__109"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "631",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "632",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "633",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__108",
                        "unk__109"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_148",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "633",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__108",
                        "unk__109"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1151",
                  "initializer": {
                    "name": "1151",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1152",
                  "initializer": {
                    "name": "1152",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1150",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__110",
                        "unk__111"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "960"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_151",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1150",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__110",
                        "unk__111"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "636",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "637",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "638",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__110",
                        "unk__111"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_152",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "638",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__110",
                        "unk__111"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1154",
                  "initializer": {
                    "name": "1154",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          160,
                          960,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        160,
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1155",
                  "initializer": {
                    "name": "1155",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          160
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        160
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1153",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__112",
                        "unk__113"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Add_153",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "628",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__106",
                        "unk__107"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1153",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__112",
                        "unk__113"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "641",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__114",
                        "unk__115"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_154",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "641",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        160,
                        "unk__114",
                        "unk__115"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1157",
                  "initializer": {
                    "name": "1157",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960,
                          160,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960,
                        160,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1158",
                  "initializer": {
                    "name": "1158",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1156",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__116",
                        "unk__117"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_157",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1156",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__116",
                        "unk__117"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "644",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "645",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "646",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__116",
                        "unk__117"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_158",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "646",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__116",
                        "unk__117"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1160",
                  "initializer": {
                    "name": "1160",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1161",
                  "initializer": {
                    "name": "1161",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          960
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        960
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1159",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__118",
                        "unk__119"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "960"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_161",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1159",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__118",
                        "unk__119"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "649",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "650",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "651",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__118",
                        "unk__119"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_162",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "651",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        960,
                        "unk__118",
                        "unk__119"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1163",
                  "initializer": {
                    "name": "1163",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          320,
                          960,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        320,
                        960,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1164",
                  "initializer": {
                    "name": "1164",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          320
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        320
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1162",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        320,
                        "unk__120",
                        "unk__121"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv_163",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1162",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        320,
                        "unk__120",
                        "unk__121"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "1166",
                  "initializer": {
                    "name": "1166",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1280,
                          320,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1280,
                        320,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1167",
                  "initializer": {
                    "name": "1167",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1280
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1280
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1165",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Clip_166",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1165",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "656",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "657",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "658",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 11,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Shape_167",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "658",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "shape",
              "value": [
                {
                  "name": "659",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Shape",
            "module": "ai.onnx",
            "version": 1,
            "description": "Takes a tensor as input and outputs an 1D int64 tensor containing the shape of the input tensor.\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "shape",
                "type": "T1",
                "description": "Shape of the input tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Input tensor can be of arbitrary type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain output to int64 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "shape",
                "code": "x = np.array(\n    [\n        [1, 2, 3],\n        [4, 5, 6],\n    ]\n).astype(np.float32)\ntest_shape(\"_example\", x)  # preserve names of original test cases\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\n\ntest_shape(\"\", x)  # preserve names of original test cases\n\ntest_shape(\"_start_1\", x, start=1)\n\ntest_shape(\"_end_1\", x, end=1)\n\ntest_shape(\"_start_negative_1\", x, start=-1)\n\ntest_shape(\"_end_negative_1\", x, end=-1)\n\ntest_shape(\"_start_1_end_negative_1\", x, start=1, end=-1)\n\ntest_shape(\"_start_1_end_2\", x, start=1, end=2)\n\ntest_shape(\"_clip_start\", x, start=-10)\n\ntest_shape(\"_clip_end\", x, end=10)"
              }
            ]
          }
        },
        {
          "name": "Gather_169",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "659",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "indices",
              "value": [
                {
                  "name": "660",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "661",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64"
            }
          ],
          "type": {
            "name": "Gather",
            "module": "ai.onnx",
            "version": 11,
            "description": "Given `data` tensor of rank r >= 1, and `indices` tensor of rank q, gather\nentries of the axis dimension of `data` (by default outer-most one as axis=0) indexed by `indices`, and concatenates\nthem in an output tensor of rank q + (r - 1).\n\naxis = 0 :\n\nLet\nk = indices[i_{0}, ..., i_{q-1}]\nThen\noutput[i_{0}, ..., i_{q-1}, j_{0}, ..., j_{r-2}] = input[k , j_{0}, ..., j_{r-2}]\n\n```\n  data = [\n      [1.0, 1.2],\n      [2.3, 3.4],\n      [4.5, 5.7],\n  ]\n  indices = [\n      [0, 1],\n      [1, 2],\n  ]\n  output = [\n      [\n          [1.0, 1.2],\n          [2.3, 3.4],\n      ],\n      [\n          [2.3, 3.4],\n          [4.5, 5.7],\n      ],\n  ]\n```\naxis = 1 :\n\nLet\nk = indices[i_{0}, ..., i_{q-1}]\nThen\noutput[j_{0}, i_{0}, ..., i_{q-1}, j_{1}, ..., j_{r-2}] = input[j_{0}, k, j_{1}, ..., j_{r-2}]\n\n```\n  data = [\n      [1.0, 1.2, 1.9],\n      [2.3, 3.4, 3.9],\n      [4.5, 5.7, 5.9],\n  ]\n  indices = [\n      [0, 2],\n  ]\n  axis = 1,\n  output = [\n      [[1.0, 1.9]],\n      [[2.3, 3.9]],\n      [[4.5, 5.9]],\n  ]\n```\n",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": false,
                "description": "Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of rank r >= 1."
              },
              {
                "name": "indices",
                "type": "Tind",
                "description": "Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Tensor of rank q + (r - 1)."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "gather_0",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=0,\n)\ndata = np.random.randn(5, 4, 3, 2).astype(np.float32)\nindices = np.array([0, 1, 3])\ny = np.take(data, indices, axis=0)\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_0\",\n)"
              },
              {
                "summary": "gather_1",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=1,\n)\ndata = np.random.randn(5, 4, 3, 2).astype(np.float32)\nindices = np.array([0, 1, 3])\ny = np.take(data, indices, axis=1)\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_1\",\n)"
              },
              {
                "summary": "gather_2d_indices",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=1,\n)\ndata = np.random.randn(3, 3).astype(np.float32)\nindices = np.array([[0, 2]])\ny = np.take(data, indices, axis=1)\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_2d_indices\",\n)"
              },
              {
                "summary": "gather_negative_indices",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=0,\n)\ndata = np.arange(10).astype(np.float32)\nindices = np.array([0, -9, -10])\ny = np.take(data, indices, axis=0)\n\n# print(y)\n# [0. 1. 0.]\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_negative_indices\",\n)"
              }
            ],
            "category": "Transform"
          }
        },
        {
          "name": "Shape_170",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "658",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "shape",
              "value": [
                {
                  "name": "662",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Shape",
            "module": "ai.onnx",
            "version": 1,
            "description": "Takes a tensor as input and outputs an 1D int64 tensor containing the shape of the input tensor.\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "shape",
                "type": "T1",
                "description": "Shape of the input tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Input tensor can be of arbitrary type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain output to int64 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "shape",
                "code": "x = np.array(\n    [\n        [1, 2, 3],\n        [4, 5, 6],\n    ]\n).astype(np.float32)\ntest_shape(\"_example\", x)  # preserve names of original test cases\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\n\ntest_shape(\"\", x)  # preserve names of original test cases\n\ntest_shape(\"_start_1\", x, start=1)\n\ntest_shape(\"_end_1\", x, end=1)\n\ntest_shape(\"_start_negative_1\", x, start=-1)\n\ntest_shape(\"_end_negative_1\", x, end=-1)\n\ntest_shape(\"_start_1_end_negative_1\", x, start=1, end=-1)\n\ntest_shape(\"_start_1_end_2\", x, start=1, end=2)\n\ntest_shape(\"_clip_start\", x, start=-10)\n\ntest_shape(\"_clip_end\", x, end=10)"
              }
            ]
          }
        },
        {
          "name": "Gather_172",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "662",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "indices",
              "value": [
                {
                  "name": "663",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "664",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64"
            }
          ],
          "type": {
            "name": "Gather",
            "module": "ai.onnx",
            "version": 11,
            "description": "Given `data` tensor of rank r >= 1, and `indices` tensor of rank q, gather\nentries of the axis dimension of `data` (by default outer-most one as axis=0) indexed by `indices`, and concatenates\nthem in an output tensor of rank q + (r - 1).\n\naxis = 0 :\n\nLet\nk = indices[i_{0}, ..., i_{q-1}]\nThen\noutput[i_{0}, ..., i_{q-1}, j_{0}, ..., j_{r-2}] = input[k , j_{0}, ..., j_{r-2}]\n\n```\n  data = [\n      [1.0, 1.2],\n      [2.3, 3.4],\n      [4.5, 5.7],\n  ]\n  indices = [\n      [0, 1],\n      [1, 2],\n  ]\n  output = [\n      [\n          [1.0, 1.2],\n          [2.3, 3.4],\n      ],\n      [\n          [2.3, 3.4],\n          [4.5, 5.7],\n      ],\n  ]\n```\naxis = 1 :\n\nLet\nk = indices[i_{0}, ..., i_{q-1}]\nThen\noutput[j_{0}, i_{0}, ..., i_{q-1}, j_{1}, ..., j_{r-2}] = input[j_{0}, k, j_{1}, ..., j_{r-2}]\n\n```\n  data = [\n      [1.0, 1.2, 1.9],\n      [2.3, 3.4, 3.9],\n      [4.5, 5.7, 5.9],\n  ]\n  indices = [\n      [0, 2],\n  ]\n  axis = 1,\n  output = [\n      [[1.0, 1.9]],\n      [[2.3, 3.9]],\n      [[4.5, 5.9]],\n  ]\n```\n",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": false,
                "description": "Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of rank r >= 1."
              },
              {
                "name": "indices",
                "type": "Tind",
                "description": "Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Tensor of rank q + (r - 1)."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "gather_0",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=0,\n)\ndata = np.random.randn(5, 4, 3, 2).astype(np.float32)\nindices = np.array([0, 1, 3])\ny = np.take(data, indices, axis=0)\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_0\",\n)"
              },
              {
                "summary": "gather_1",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=1,\n)\ndata = np.random.randn(5, 4, 3, 2).astype(np.float32)\nindices = np.array([0, 1, 3])\ny = np.take(data, indices, axis=1)\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_1\",\n)"
              },
              {
                "summary": "gather_2d_indices",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=1,\n)\ndata = np.random.randn(3, 3).astype(np.float32)\nindices = np.array([[0, 2]])\ny = np.take(data, indices, axis=1)\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_2d_indices\",\n)"
              },
              {
                "summary": "gather_negative_indices",
                "code": "node = onnx.helper.make_node(\n    \"Gather\",\n    inputs=[\"data\", \"indices\"],\n    outputs=[\"y\"],\n    axis=0,\n)\ndata = np.arange(10).astype(np.float32)\nindices = np.array([0, -9, -10])\ny = np.take(data, indices, axis=0)\n\n# print(y)\n# [0. 1. 0.]\n\nexpect(\n    node,\n    inputs=[data, indices.astype(np.int64)],\n    outputs=[y],\n    name=\"test_gather_negative_indices\",\n)"
              }
            ],
            "category": "Transform"
          }
        },
        {
          "name": "GlobalAveragePool_173",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "658",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "665",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Unsqueeze_174",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "661",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "expanded",
              "value": [
                {
                  "name": "666",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axes",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0"
                ]
              }
            }
          ],
          "type": {
            "name": "Unsqueeze",
            "module": "ai.onnx",
            "version": 11,
            "description": "Insert single-dimensional entries to the shape of an input tensor (`data`).\nTakes one required argument `axes` - which contains a list of dimension indices and this operator will insert a dimension of value `1` into the corresponding index of the output tensor (`expanded`).\n\nFor example:\n  Given an input tensor (`data`) of shape [3, 4, 5], then\n  Unsqueeze(data, axes=[0, 4]) outputs a tensor (`expanded`) containing same data as `data` but with shape [1, 3, 4, 5, 1].\n\nThe attribute `axes` should not contain any duplicate entries. It is an error if it contains duplicates.\nThe rank of the output tensor (`output_rank`) is the rank of the input tensor (`data`) plus the number of values in `axes`.\nEach value in `axes` should be within the (inclusive) range [-output_rank , output_rank - 1].\nThe order of values in `axes` does not matter and can come in any order.\n\n",
            "attributes": [
              {
                "name": "axes",
                "type": "int64[]",
                "required": true,
                "description": "List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded)."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Original tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "expanded",
                "type": "T",
                "description": "Reshaped tensor with same data as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "unsqueeze_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 1, 5).astype(np.float32)\naxes = np.array([-2]).astype(np.int64)\ny = np.expand_dims(x, axis=-2)\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_negative_axes\")"
              },
              {
                "summary": "unsqueeze_one_axis",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\n\nfor i in range(x.ndim):\n    axes = np.array([i]).astype(np.int64)\n    node = onnx.helper.make_node(\n        \"Unsqueeze\",\n        inputs=[\"x\", \"axes\"],\n        outputs=[\"y\"],\n    )\n    y = np.expand_dims(x, axis=i)\n\n    expect(\n        node,\n        inputs=[x, axes],\n        outputs=[y],\n        name=\"test_unsqueeze_axis_\" + str(i),\n    )"
              },
              {
                "summary": "unsqueeze_three_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([2, 4, 5]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_three_axes\")"
              },
              {
                "summary": "unsqueeze_two_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([1, 4]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=1)\ny = np.expand_dims(y, axis=4)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_two_axes\")"
              },
              {
                "summary": "unsqueeze_unsorted_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([5, 4, 2]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_unsorted_axes\")"
              }
            ],
            "category": "Transform"
          }
        },
        {
          "name": "Unsqueeze_175",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "664",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "expanded",
              "value": [
                {
                  "name": "667",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axes",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0"
                ]
              }
            }
          ],
          "type": {
            "name": "Unsqueeze",
            "module": "ai.onnx",
            "version": 11,
            "description": "Insert single-dimensional entries to the shape of an input tensor (`data`).\nTakes one required argument `axes` - which contains a list of dimension indices and this operator will insert a dimension of value `1` into the corresponding index of the output tensor (`expanded`).\n\nFor example:\n  Given an input tensor (`data`) of shape [3, 4, 5], then\n  Unsqueeze(data, axes=[0, 4]) outputs a tensor (`expanded`) containing same data as `data` but with shape [1, 3, 4, 5, 1].\n\nThe attribute `axes` should not contain any duplicate entries. It is an error if it contains duplicates.\nThe rank of the output tensor (`output_rank`) is the rank of the input tensor (`data`) plus the number of values in `axes`.\nEach value in `axes` should be within the (inclusive) range [-output_rank , output_rank - 1].\nThe order of values in `axes` does not matter and can come in any order.\n\n",
            "attributes": [
              {
                "name": "axes",
                "type": "int64[]",
                "required": true,
                "description": "List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded)."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Original tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "expanded",
                "type": "T",
                "description": "Reshaped tensor with same data as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "unsqueeze_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 1, 5).astype(np.float32)\naxes = np.array([-2]).astype(np.int64)\ny = np.expand_dims(x, axis=-2)\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_negative_axes\")"
              },
              {
                "summary": "unsqueeze_one_axis",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\n\nfor i in range(x.ndim):\n    axes = np.array([i]).astype(np.int64)\n    node = onnx.helper.make_node(\n        \"Unsqueeze\",\n        inputs=[\"x\", \"axes\"],\n        outputs=[\"y\"],\n    )\n    y = np.expand_dims(x, axis=i)\n\n    expect(\n        node,\n        inputs=[x, axes],\n        outputs=[y],\n        name=\"test_unsqueeze_axis_\" + str(i),\n    )"
              },
              {
                "summary": "unsqueeze_three_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([2, 4, 5]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_three_axes\")"
              },
              {
                "summary": "unsqueeze_two_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([1, 4]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=1)\ny = np.expand_dims(y, axis=4)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_two_axes\")"
              },
              {
                "summary": "unsqueeze_unsorted_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([5, 4, 2]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_unsorted_axes\")"
              }
            ],
            "category": "Transform"
          }
        },
        {
          "name": "Concat_176",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "666",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                },
                {
                  "name": "667",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "668",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        2
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64"
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Reshape_177",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "665",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "shape",
              "value": [
                {
                  "name": "668",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        2
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "reshaped",
              "value": [
                {
                  "name": "669",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Reshape",
            "module": "ai.onnx",
            "version": 5,
            "description": "Reshape the input tensor similar to numpy.reshape.\nFirst input is the data tensor, second input is a shape tensor which specifies the output shape. It outputs the reshaped tensor.\nAt most one dimension of the new shape can be -1. In this case, the value is\ninferred from the size of the tensor and the remaining dimensions. A dimension\ncould also be 0, in which case the actual dimension value is unchanged (i.e. taken\nfrom the input tensor). Shape (second input) could be an empty shape, which means converting to a scalar.\nThe input tensor's shape and the output tensor's shape are required to have the same number of elements.",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              },
              {
                "name": "shape",
                "type": "tensor(int64)",
                "description": "Specified shape for output."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "reshaped",
                "type": "T",
                "description": "Reshaped data."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "allowzero",
                "code": "original_shape = [0, 3, 4]\ntest_cases = {\n    \"allowzero_reordered\": np.array([3, 4, 0], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n        allowzero=1,  # if allowzero=1, final shape = (3, 4, 0)\n        # if allowzero=0, final shape = (3, 4, 4)\n    )\n\n    reshaped = reshape_reference_implementation(data, shape, allowzero=1)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              },
              {
                "summary": "reshape",
                "code": "original_shape = [2, 3, 4]\ntest_cases = {\n    \"reordered_all_dims\": np.array([4, 2, 3], dtype=np.int64),\n    \"reordered_last_dims\": np.array([2, 4, 3], dtype=np.int64),\n    \"reduced_dims\": np.array([2, 12], dtype=np.int64),\n    \"extended_dims\": np.array([2, 3, 2, 2], dtype=np.int64),\n    \"one_dim\": np.array([24], dtype=np.int64),\n    \"negative_dim\": np.array([2, -1, 2], dtype=np.int64),\n    \"negative_extended_dims\": np.array([-1, 2, 3, 4], dtype=np.int64),\n    \"zero_dim\": np.array([2, 0, 4, 1], dtype=np.int64),\n    \"zero_and_negative_dim\": np.array([2, 0, 1, -1], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n    )\n\n    reshaped = reshape_reference_implementation(data, shape)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              }
            ],
            "category": "Shape"
          }
        },
        {
          "name": "MatMul_178",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "669",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1168",
                  "initializer": {
                    "name": "1168",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1280,
                          320
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1280,
                        320
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "671",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "MatMul",
            "module": "ai.onnx",
            "version": 9,
            "description": "Matrix product that behaves like [numpy.matmul](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "N-dimensional matrix A"
              },
              {
                "name": "B",
                "type": "T",
                "description": "N-dimensional matrix B"
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Matrix multiply results from A * B"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float/int tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "matmul",
                "code": "node = onnx.helper.make_node(\n    \"MatMul\",\n    inputs=[\"a\", \"b\"],\n    outputs=[\"c\"],\n)\n\n# 2d\na = np.random.randn(3, 4).astype(np.float32)\nb = np.random.randn(4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_2d\")\n\n# 3d\na = np.random.randn(2, 3, 4).astype(np.float32)\nb = np.random.randn(2, 4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_3d\")\n\n# 4d\na = np.random.randn(1, 2, 3, 4).astype(np.float32)\nb = np.random.randn(1, 2, 4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_4d\")"
              }
            ]
          }
        },
        {
          "name": "Relu_179",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "671",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "672",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "MatMul_180",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "672",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1169",
                  "initializer": {
                    "name": "1169",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          320,
                          1280
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        320,
                        1280
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "674",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "MatMul",
            "module": "ai.onnx",
            "version": 9,
            "description": "Matrix product that behaves like [numpy.matmul](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "N-dimensional matrix A"
              },
              {
                "name": "B",
                "type": "T",
                "description": "N-dimensional matrix B"
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Matrix multiply results from A * B"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float/int tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "matmul",
                "code": "node = onnx.helper.make_node(\n    \"MatMul\",\n    inputs=[\"a\", \"b\"],\n    outputs=[\"c\"],\n)\n\n# 2d\na = np.random.randn(3, 4).astype(np.float32)\nb = np.random.randn(4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_2d\")\n\n# 3d\na = np.random.randn(2, 3, 4).astype(np.float32)\nb = np.random.randn(2, 4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_3d\")\n\n# 4d\na = np.random.randn(1, 2, 3, 4).astype(np.float32)\nb = np.random.randn(1, 2, 4, 3).astype(np.float32)\nc = np.matmul(a, b)\nexpect(node, inputs=[a, b], outputs=[c], name=\"test_matmul_4d\")"
              }
            ]
          }
        },
        {
          "name": "Sigmoid_181",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "674",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "675",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 6,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Unsqueeze_182",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "661",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "expanded",
              "value": [
                {
                  "name": "678",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axes",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0"
                ]
              }
            }
          ],
          "type": {
            "name": "Unsqueeze",
            "module": "ai.onnx",
            "version": 11,
            "description": "Insert single-dimensional entries to the shape of an input tensor (`data`).\nTakes one required argument `axes` - which contains a list of dimension indices and this operator will insert a dimension of value `1` into the corresponding index of the output tensor (`expanded`).\n\nFor example:\n  Given an input tensor (`data`) of shape [3, 4, 5], then\n  Unsqueeze(data, axes=[0, 4]) outputs a tensor (`expanded`) containing same data as `data` but with shape [1, 3, 4, 5, 1].\n\nThe attribute `axes` should not contain any duplicate entries. It is an error if it contains duplicates.\nThe rank of the output tensor (`output_rank`) is the rank of the input tensor (`data`) plus the number of values in `axes`.\nEach value in `axes` should be within the (inclusive) range [-output_rank , output_rank - 1].\nThe order of values in `axes` does not matter and can come in any order.\n\n",
            "attributes": [
              {
                "name": "axes",
                "type": "int64[]",
                "required": true,
                "description": "List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded)."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Original tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "expanded",
                "type": "T",
                "description": "Reshaped tensor with same data as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "unsqueeze_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 1, 5).astype(np.float32)\naxes = np.array([-2]).astype(np.int64)\ny = np.expand_dims(x, axis=-2)\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_negative_axes\")"
              },
              {
                "summary": "unsqueeze_one_axis",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\n\nfor i in range(x.ndim):\n    axes = np.array([i]).astype(np.int64)\n    node = onnx.helper.make_node(\n        \"Unsqueeze\",\n        inputs=[\"x\", \"axes\"],\n        outputs=[\"y\"],\n    )\n    y = np.expand_dims(x, axis=i)\n\n    expect(\n        node,\n        inputs=[x, axes],\n        outputs=[y],\n        name=\"test_unsqueeze_axis_\" + str(i),\n    )"
              },
              {
                "summary": "unsqueeze_three_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([2, 4, 5]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_three_axes\")"
              },
              {
                "summary": "unsqueeze_two_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([1, 4]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=1)\ny = np.expand_dims(y, axis=4)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_two_axes\")"
              },
              {
                "summary": "unsqueeze_unsorted_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([5, 4, 2]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_unsorted_axes\")"
              }
            ],
            "category": "Transform"
          }
        },
        {
          "name": "Unsqueeze_183",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "664",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "expanded",
              "value": [
                {
                  "name": "679",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axes",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0"
                ]
              }
            }
          ],
          "type": {
            "name": "Unsqueeze",
            "module": "ai.onnx",
            "version": 11,
            "description": "Insert single-dimensional entries to the shape of an input tensor (`data`).\nTakes one required argument `axes` - which contains a list of dimension indices and this operator will insert a dimension of value `1` into the corresponding index of the output tensor (`expanded`).\n\nFor example:\n  Given an input tensor (`data`) of shape [3, 4, 5], then\n  Unsqueeze(data, axes=[0, 4]) outputs a tensor (`expanded`) containing same data as `data` but with shape [1, 3, 4, 5, 1].\n\nThe attribute `axes` should not contain any duplicate entries. It is an error if it contains duplicates.\nThe rank of the output tensor (`output_rank`) is the rank of the input tensor (`data`) plus the number of values in `axes`.\nEach value in `axes` should be within the (inclusive) range [-output_rank , output_rank - 1].\nThe order of values in `axes` does not matter and can come in any order.\n\n",
            "attributes": [
              {
                "name": "axes",
                "type": "int64[]",
                "required": true,
                "description": "List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded)."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Original tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "expanded",
                "type": "T",
                "description": "Reshaped tensor with same data as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "unsqueeze_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 1, 5).astype(np.float32)\naxes = np.array([-2]).astype(np.int64)\ny = np.expand_dims(x, axis=-2)\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_negative_axes\")"
              },
              {
                "summary": "unsqueeze_one_axis",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\n\nfor i in range(x.ndim):\n    axes = np.array([i]).astype(np.int64)\n    node = onnx.helper.make_node(\n        \"Unsqueeze\",\n        inputs=[\"x\", \"axes\"],\n        outputs=[\"y\"],\n    )\n    y = np.expand_dims(x, axis=i)\n\n    expect(\n        node,\n        inputs=[x, axes],\n        outputs=[y],\n        name=\"test_unsqueeze_axis_\" + str(i),\n    )"
              },
              {
                "summary": "unsqueeze_three_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([2, 4, 5]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_three_axes\")"
              },
              {
                "summary": "unsqueeze_two_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([1, 4]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=1)\ny = np.expand_dims(y, axis=4)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_two_axes\")"
              },
              {
                "summary": "unsqueeze_unsorted_axes",
                "code": "x = np.random.randn(3, 4, 5).astype(np.float32)\naxes = np.array([5, 4, 2]).astype(np.int64)\n\nnode = onnx.helper.make_node(\n    \"Unsqueeze\",\n    inputs=[\"x\", \"axes\"],\n    outputs=[\"y\"],\n)\ny = np.expand_dims(x, axis=2)\ny = np.expand_dims(y, axis=4)\ny = np.expand_dims(y, axis=5)\n\nexpect(node, inputs=[x, axes], outputs=[y], name=\"test_unsqueeze_unsorted_axes\")"
              }
            ],
            "category": "Transform"
          }
        },
        {
          "name": "Concat_184",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "678",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                },
                {
                  "name": "679",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                },
                {
                  "name": "1170",
                  "initializer": {
                    "name": "1170",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                },
                {
                  "name": "1171",
                  "initializer": {
                    "name": "1171",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "682",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64"
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Reshape_185",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "675",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "shape",
              "value": [
                {
                  "name": "682",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "reshaped",
              "value": [
                {
                  "name": "683",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Reshape",
            "module": "ai.onnx",
            "version": 5,
            "description": "Reshape the input tensor similar to numpy.reshape.\nFirst input is the data tensor, second input is a shape tensor which specifies the output shape. It outputs the reshaped tensor.\nAt most one dimension of the new shape can be -1. In this case, the value is\ninferred from the size of the tensor and the remaining dimensions. A dimension\ncould also be 0, in which case the actual dimension value is unchanged (i.e. taken\nfrom the input tensor). Shape (second input) could be an empty shape, which means converting to a scalar.\nThe input tensor's shape and the output tensor's shape are required to have the same number of elements.",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              },
              {
                "name": "shape",
                "type": "tensor(int64)",
                "description": "Specified shape for output."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "reshaped",
                "type": "T",
                "description": "Reshaped data."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "allowzero",
                "code": "original_shape = [0, 3, 4]\ntest_cases = {\n    \"allowzero_reordered\": np.array([3, 4, 0], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n        allowzero=1,  # if allowzero=1, final shape = (3, 4, 0)\n        # if allowzero=0, final shape = (3, 4, 4)\n    )\n\n    reshaped = reshape_reference_implementation(data, shape, allowzero=1)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              },
              {
                "summary": "reshape",
                "code": "original_shape = [2, 3, 4]\ntest_cases = {\n    \"reordered_all_dims\": np.array([4, 2, 3], dtype=np.int64),\n    \"reordered_last_dims\": np.array([2, 4, 3], dtype=np.int64),\n    \"reduced_dims\": np.array([2, 12], dtype=np.int64),\n    \"extended_dims\": np.array([2, 3, 2, 2], dtype=np.int64),\n    \"one_dim\": np.array([24], dtype=np.int64),\n    \"negative_dim\": np.array([2, -1, 2], dtype=np.int64),\n    \"negative_extended_dims\": np.array([-1, 2, 3, 4], dtype=np.int64),\n    \"zero_dim\": np.array([2, 0, 4, 1], dtype=np.int64),\n    \"zero_and_negative_dim\": np.array([2, 0, 1, -1], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n    )\n\n    reshaped = reshape_reference_implementation(data, shape)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              }
            ],
            "category": "Shape"
          }
        },
        {
          "name": "Shape_186",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "658",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "shape",
              "value": [
                {
                  "name": "684",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Shape",
            "module": "ai.onnx",
            "version": 1,
            "description": "Takes a tensor as input and outputs an 1D int64 tensor containing the shape of the input tensor.\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "shape",
                "type": "T1",
                "description": "Shape of the input tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Input tensor can be of arbitrary type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain output to int64 tensor.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "shape",
                "code": "x = np.array(\n    [\n        [1, 2, 3],\n        [4, 5, 6],\n    ]\n).astype(np.float32)\ntest_shape(\"_example\", x)  # preserve names of original test cases\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\n\ntest_shape(\"\", x)  # preserve names of original test cases\n\ntest_shape(\"_start_1\", x, start=1)\n\ntest_shape(\"_end_1\", x, end=1)\n\ntest_shape(\"_start_negative_1\", x, start=-1)\n\ntest_shape(\"_end_negative_1\", x, end=-1)\n\ntest_shape(\"_start_1_end_negative_1\", x, start=1, end=-1)\n\ntest_shape(\"_start_1_end_2\", x, start=1, end=2)\n\ntest_shape(\"_clip_start\", x, start=-10)\n\ntest_shape(\"_clip_end\", x, end=10)"
              }
            ]
          }
        },
        {
          "name": "Expand_187",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "683",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "shape",
              "value": [
                {
                  "name": "684",
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "685",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Expand",
            "module": "ai.onnx",
            "version": 8,
            "description": "Broadcast the input tensor following the given shape and the broadcast rule.\nThe broadcast rule is similar to numpy.array(input) * numpy.ones(shape):\nDimensions are right alignment;\nTwo corresponding dimensions must have the same value, or one of them is equal to 1.\nAlso, this operator is similar to numpy.broadcast_to(input, shape),\nbut the major difference is numpy.broadcast_to() does not allow shape to be smaller than input.size().\nIt is possible that the output.shape is not equal to shape, when some dimensions in shape is equal to 1,\nor the shape.ndim < input.shape.ndim.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor"
              },
              {
                "name": "shape",
                "type": "tensor(int64)",
                "description": "A 1-D tensor indicates the shape you want to expand to, following the broadcast rule"
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "dim_changed",
                "code": "node = onnx.helper.make_node(\n    \"Expand\",\n    inputs=[\"data\", \"new_shape\"],\n    outputs=[\"expanded\"],\n)\nshape = [3, 1]\ndata = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)\n# print(data)\n# [[1.], [2.], [3.]]\nnew_shape = [2, 1, 6]\nexpanded = data * np.ones(new_shape, dtype=np.float32)\n# print(expanded)\n# [[[1., 1., 1., 1., 1., 1.],\n#  [2., 2., 2., 2., 2., 2.],\n#  [3., 3., 3., 3., 3., 3.]],\n#\n# [[1., 1., 1., 1., 1., 1.],\n#  [2., 2., 2., 2., 2., 2.],\n#  [3., 3., 3., 3., 3., 3.]]]\nnew_shape = np.array(new_shape, dtype=np.int64)\nexpect(\n    node,\n    inputs=[data, new_shape],\n    outputs=[expanded],\n    name=\"test_expand_dim_changed\",\n)"
              },
              {
                "summary": "dim_unchanged",
                "code": "node = onnx.helper.make_node(\n    \"Expand\",\n    inputs=[\"data\", \"new_shape\"],\n    outputs=[\"expanded\"],\n)\nshape = [3, 1]\nnew_shape = [3, 4]\ndata = np.reshape(np.arange(1, np.prod(shape) + 1, dtype=np.float32), shape)\n# print(data)\n# [[1.], [2.], [3.]]\nexpanded = np.tile(data, 4)\n# print(expanded)\n# [[1., 1., 1., 1.],\n# [2., 2., 2., 2.],\n# [3., 3., 3., 3.]]\nnew_shape = np.array(new_shape, dtype=np.int64)\nexpect(\n    node,\n    inputs=[data, new_shape],\n    outputs=[expanded],\n    name=\"test_expand_dim_unchanged\",\n)"
              }
            ]
          }
        },
        {
          "name": "Mul_188",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "658",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1280,
                        "unk__122",
                        "unk__123"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "685",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "686",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 7,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to high-precision numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv_231",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1018",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__4",
                        "unk__5"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.tohr_enc2x.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.tohr_enc2x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.tohr_enc2x.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.tohr_enc2x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "741",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_236",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "741",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "743",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "744",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "742",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "745",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "746",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_237",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "746",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.tohr_enc2x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.tohr_enc2x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.tohr_enc2x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.tohr_enc2x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.tohr_enc2x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.tohr_enc2x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.tohr_enc2x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.tohr_enc2x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "747",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_242",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "741",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "749",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "750",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "748",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "751",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "752",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_245",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "752",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "753",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "754",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "755",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_246",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "747",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                },
                {
                  "name": "755",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "756",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_247",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "756",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "757",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_266",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "476",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        24,
                        "unk__18",
                        "unk__19"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.tohr_enc4x.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.tohr_enc4x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.tohr_enc4x.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.tohr_enc4x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "776",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_271",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "776",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "778",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "779",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "777",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "780",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "781",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_272",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "781",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.tohr_enc4x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.tohr_enc4x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.tohr_enc4x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.tohr_enc4x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.tohr_enc4x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.tohr_enc4x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.tohr_enc4x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.tohr_enc4x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "782",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_277",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "776",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "784",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "785",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "783",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "786",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "787",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_280",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "787",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "788",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "789",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "790",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_281",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "782",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                },
                {
                  "name": "790",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        16,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "791",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_282",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "791",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "792",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_190_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "686",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_190_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_190_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "690",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_190_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_190_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1172",
                  "initializer": {
                    "name": "1172",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_190_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_190",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_190_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_190_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_190_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_190_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_190_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_190_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "691",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Conv_191",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "691",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "lr_branch.conv_lr16x.layers.0.weight",
                  "initializer": {
                    "name": "lr_branch.conv_lr16x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96,
                          1280,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96,
                        1280,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "lr_branch.conv_lr16x.layers.0.bias",
                  "initializer": {
                    "name": "lr_branch.conv_lr16x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "692",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_196",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "692",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "694",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "695",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 48,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "693",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "696",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "697",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_197",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "697",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "lr_branch.conv_lr16x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "lr_branch.conv_lr16x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          48
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        48
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "lr_branch.conv_lr16x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "lr_branch.conv_lr16x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          48
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        48
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "lr_branch.conv_lr16x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "lr_branch.conv_lr16x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          48
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        48
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "lr_branch.conv_lr16x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "lr_branch.conv_lr16x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          48
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        48
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "698",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_202",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "692",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "700",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 48,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "701",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "699",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "702",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "703",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_205",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "703",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "704",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          48
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        48
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "705",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          48
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        48
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "706",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_206",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "698",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "706",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "707",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_207",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "707",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "708",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_209_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "708",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_209_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_209_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "712",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_209_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_209_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1173",
                  "initializer": {
                    "name": "1173",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_209_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_209",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_209_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_209_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_209_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_209_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_209_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_209_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "713",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Conv_210",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "713",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "lr_branch.conv_lr8x.layers.0.weight",
                  "initializer": {
                    "name": "lr_branch.conv_lr8x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          96,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        96,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "lr_branch.conv_lr8x.layers.0.bias",
                  "initializer": {
                    "name": "lr_branch.conv_lr8x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "714",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_215",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "714",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "716",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "717",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "715",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "718",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "719",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_216",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "719",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "lr_branch.conv_lr8x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "lr_branch.conv_lr8x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "lr_branch.conv_lr8x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "lr_branch.conv_lr8x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "lr_branch.conv_lr8x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "lr_branch.conv_lr8x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "lr_branch.conv_lr8x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "lr_branch.conv_lr8x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "720",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_221",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "714",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "722",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "723",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "721",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "724",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "725",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_224",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "725",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "726",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "727",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "728",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_225",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "720",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "728",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "729",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_226",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "729",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "730",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_228_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "graph_input_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_228_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_228_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "734",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_228_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_228_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1174",
                  "initializer": {
                    "name": "1174",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_228_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_228",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_228_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_228_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_228_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_228_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        3,
                        "unk__125",
                        "unk__126"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_228_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_228_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        3,
                        "unk__125",
                        "unk__126"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "735",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        3,
                        "unk__125",
                        "unk__126"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Concat_248",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "735",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        3,
                        "unk__125",
                        "unk__126"
                      ]
                    }
                  }
                },
                {
                  "name": "757",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "758",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        35,
                        "unk__125",
                        "unk__126"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Conv_249",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "758",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        35,
                        "unk__125",
                        "unk__126"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_enc2x.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_enc2x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          35,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        35,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_enc2x.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_enc2x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "759",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_254",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "759",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "761",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "762",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "760",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "763",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "764",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_255",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "764",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_enc2x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_enc2x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_enc2x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_enc2x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_enc2x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_enc2x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_enc2x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_enc2x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "765",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_260",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "759",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "767",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "768",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "766",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "769",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "770",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_263",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "770",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "771",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "772",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "773",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_264",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "765",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                },
                {
                  "name": "773",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        16,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "774",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_265",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "774",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "775",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Concat_283",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "775",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                },
                {
                  "name": "792",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__134",
                        "unk__135"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "793",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Conv_284",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "793",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__132",
                        "unk__133"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_enc4x.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_enc4x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          64,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        64,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_enc4x.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_enc4x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "794",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_289",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "794",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "796",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "797",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "795",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "798",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "799",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_290",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "799",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_enc4x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_enc4x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_enc4x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_enc4x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_enc4x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_enc4x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_enc4x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_enc4x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "800",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_295",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "794",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "802",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "803",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "801",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "804",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "805",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_298",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "805",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "806",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "807",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "808",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_299",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "800",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                },
                {
                  "name": "808",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        32,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "809",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_300",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "809",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "810",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_230_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "graph_input_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_230_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_230_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "739",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_230_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_230_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1175",
                  "initializer": {
                    "name": "1175",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_230_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_230",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_230_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_230_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_230_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_230_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "unk__127",
                        3,
                        "unk__128",
                        "unk__129"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_230_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_230_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "unk__127",
                        3,
                        "unk__128",
                        "unk__129"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "740",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__127",
                        3,
                        "unk__128",
                        "unk__129"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_302_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "730",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_302_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_302_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "814",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_302_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_302_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1176",
                  "initializer": {
                    "name": "1176",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_302_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_302",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_302_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_302_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_302_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_302_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_302_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_302_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "815",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Concat_303",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "810",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__124",
                        64,
                        "unk__136",
                        "unk__137"
                      ]
                    }
                  }
                },
                {
                  "name": "815",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "740",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "unk__127",
                        3,
                        "unk__128",
                        "unk__129"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "816",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Conv_304",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "816",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.0.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.0.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          99,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        99,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.0.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.0.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "817",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_309",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "817",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "819",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "820",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "818",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "821",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "822",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_310",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "822",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.0.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "823",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_315",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "817",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "825",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "826",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "824",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "827",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "828",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_318",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "828",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "829",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "830",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "831",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_319",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "823",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "831",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "832",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_320",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "832",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "833",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_321",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "833",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.1.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.1.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          64,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        64,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.1.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.1.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "834",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_326",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "834",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "836",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "837",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "835",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "838",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "839",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_327",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "839",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.1.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "840",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_332",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "834",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "842",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "843",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "841",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "844",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "845",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_335",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "845",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "846",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "847",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "848",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_336",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "840",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "848",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "849",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_337",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "849",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "850",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_338",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "850",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.2.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.2.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          64,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        64,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.2.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.2.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "851",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_343",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "851",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "853",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "854",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "852",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "855",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "856",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_344",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "856",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_hr4x.2.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "857",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_349",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "851",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "859",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "860",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "858",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "861",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "862",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_352",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "862",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "863",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "864",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "865",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_353",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "857",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "865",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "866",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_354",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "866",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "867",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_356_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "867",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_356_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_356_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "871",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_356_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_356_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1177",
                  "initializer": {
                    "name": "1177",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_356_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_356",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_356_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_356_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_356_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_356_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_356_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_356_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "872",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Concat_357",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "872",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "757",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        32,
                        "unk__130",
                        "unk__131"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "873",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Conv_358",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "873",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.0.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.0.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64,
                          64,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64,
                        64,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.0.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.0.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          64
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "874",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_363",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "874",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "876",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "877",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "875",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "878",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "879",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_364",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "879",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.0.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "880",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_369",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "874",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "882",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 32,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "883",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "881",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "884",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "885",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_372",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "885",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "886",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "887",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "888",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_373",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "880",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "888",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "889",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_374",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "889",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "890",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_375",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "890",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.1.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.1.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          64,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        64,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.1.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.1.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "891",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_380",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "891",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "893",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "894",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "892",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "895",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "896",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_381",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "896",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.1.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "897",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_386",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "891",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "899",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "900",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "898",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "901",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "902",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_389",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "902",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "903",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "904",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "905",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_390",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "897",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "905",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "906",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_391",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "906",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "907",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_392",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "907",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.2.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.2.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          32,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        32,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.2.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.2.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "908",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_397",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "908",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "910",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "911",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "909",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "912",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "913",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_398",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "913",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.2.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "914",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_403",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "908",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "916",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "917",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "915",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "918",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "919",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_406",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "919",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "920",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "921",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "922",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_407",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "914",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "922",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "923",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_408",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "923",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "924",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_409",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "924",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.3.layers.0.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.3.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          32,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        32,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.3.layers.0.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.3.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "925",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_414",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "925",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "927",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "928",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "926",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "929",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "930",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_415",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "930",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "hr_branch.conv_hr2x.3.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "931",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_420",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "925",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "933",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "934",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "932",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "935",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "936",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_423",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "936",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "937",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "938",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "939",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_424",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "931",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "939",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "940",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_425",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "940",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "941",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_427_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "730",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_427_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_427_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "945",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_427_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_427_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1178",
                  "initializer": {
                    "name": "1178",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_427_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_427",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_427_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_427_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_427_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_427_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_427_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_427_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "946",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Conv_428",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "946",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "f_branch.conv_lr4x.layers.0.weight",
                  "initializer": {
                    "name": "f_branch.conv_lr4x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          32,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        32,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "f_branch.conv_lr4x.layers.0.bias",
                  "initializer": {
                    "name": "f_branch.conv_lr4x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "947",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_433",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "947",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "949",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "950",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "948",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "951",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "952",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_434",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "952",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "f_branch.conv_lr4x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "f_branch.conv_lr4x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "f_branch.conv_lr4x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "f_branch.conv_lr4x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "f_branch.conv_lr4x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "f_branch.conv_lr4x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "f_branch.conv_lr4x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "f_branch.conv_lr4x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "953",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_439",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "947",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "955",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "956",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "954",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "957",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "958",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_442",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "958",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "959",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "960",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "961",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_443",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "953",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "961",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "962",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_444",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "962",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "963",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_446_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "963",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_446_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_446_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "967",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_446_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_446_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1179",
                  "initializer": {
                    "name": "1179",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_446_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_446",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_446_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_446_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_446_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_446_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_446_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_446_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "968",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Concat_447",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "968",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "941",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "969",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Conv_448",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "969",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "f_branch.conv_f2x.layers.0.weight",
                  "initializer": {
                    "name": "f_branch.conv_f2x.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32,
                          64,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32,
                        64,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "f_branch.conv_f2x.layers.0.bias",
                  "initializer": {
                    "name": "f_branch.conv_f2x.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "970",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_453",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "970",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "972",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "973",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "971",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "974",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "975",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_454",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "975",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "f_branch.conv_f2x.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "f_branch.conv_f2x.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "f_branch.conv_f2x.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "f_branch.conv_f2x.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "f_branch.conv_f2x.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "f_branch.conv_f2x.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "f_branch.conv_f2x.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "f_branch.conv_f2x.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "976",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_459",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "970",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "978",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 16,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "979",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "977",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "980",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "981",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_462",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "981",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "982",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "983",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "984",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_463",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "976",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "984",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "985",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_464",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "985",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "986",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Resize_466_input_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "986",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_466_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_466_input_cast1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "990",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_466_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_466_input_cast2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1180",
                  "initializer": {
                    "name": "1180",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Resize_466_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Resize_466",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Resize_466_input_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "Resize_466_input_cast_1",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "Resize_466_input_cast_2",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Resize_466_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "coordinate_transformation_mode",
              "type": "string",
              "value": "pytorch_half_pixel"
            },
            {
              "name": "cubic_coeff_a",
              "type": "float32",
              "value": -0.75
            },
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            },
            {
              "name": "nearest_mode",
              "type": "string",
              "value": "floor"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 11,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n  output_dimension = floor(input_dimension * (roi_end - roi_start) * scale) if input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input \"roi\", scale = length_resized / length_original, <br/>\n\nif coordinate_transformation_mode is \"half_pixel\", <br/>\nx_original = (x_resized + 0.5) / scale - 0.5, <br/>\n\nif coordinate_transformation_mode is \"pytorch_half_pixel\", <br/>\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>\n\nif coordinate_transformation_mode is \"align_corners\", <br/>\nx_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>\n\nif coordinate_transformation_mode is \"asymmetric\", <br/>\nx_original = x_resized / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_half_pixel_for_nn\", <br/>\nx_original = (x_resized + 0.5) / scale, <br/>\n\nif coordinate_transformation_mode is \"tf_crop_and_resize\", <br/>\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if \"mode\" is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: nearest (default), linear and cubic. The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor."
              }
            ],
            "min_input": 3,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Resize_466_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "Resize_466_output_cast_0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "991",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float16"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        },
        {
          "name": "Concat_467",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "991",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "graph_input_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        3,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "992",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Conv_468",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "992",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "f_branch.conv_f.0.layers.0.weight",
                  "initializer": {
                    "name": "f_branch.conv_f.0.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16,
                          35,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16,
                        35,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "f_branch.conv_f.0.layers.0.bias",
                  "initializer": {
                    "name": "f_branch.conv_f.0.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "993",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Slice_473",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "993",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "995",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "996",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 8,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "994",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "997",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "998",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "BatchNormalization_474",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "998",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "f_branch.conv_f.0.layers.1.bnorm.weight",
                  "initializer": {
                    "name": "f_branch.conv_f.0.layers.1.bnorm.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "f_branch.conv_f.0.layers.1.bnorm.bias",
                  "initializer": {
                    "name": "f_branch.conv_f.0.layers.1.bnorm.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "mean",
              "value": [
                {
                  "name": "f_branch.conv_f.0.layers.1.bnorm.running_mean",
                  "initializer": {
                    "name": "f_branch.conv_f.0.layers.1.bnorm.running_mean",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "var",
              "value": [
                {
                  "name": "f_branch.conv_f.0.layers.1.bnorm.running_var",
                  "initializer": {
                    "name": "f_branch.conv_f.0.layers.1.bnorm.running_var",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "999",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            },
            {
              "name": "momentum",
              "type": "float32",
              "value": 0.8999999761581421
            }
          ],
          "type": {
            "name": "BatchNormalization",
            "module": "ai.onnx",
            "version": 9,
            "description": "Carries out batch normalization as described in the paper\nhttps://arxiv.org/abs/1502.03167. Depending on the mode it is being run,\nthere are multiple cases for the number of outputs, which we list below:\n\nOutput case #1: Y, mean, var, saved_mean, saved_var (training mode)\nOutput case #2: Y (test mode)\n\nFor previous (depreciated) non-spatial cases, implementors are suggested\nto flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.\nThis operator has **optional** inputs/outputs. See [the doc](https://github.com/onnx/onnx/blob/master/docs/IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              },
              {
                "name": "momentum",
                "type": "float32",
                "required": false,
                "default": 0.8999999761581421,
                "description": "Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum)."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1"
              },
              {
                "name": "scale",
                "type": "T",
                "description": "Scale tensor of shape (C)."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Bias tensor of shape (C)."
              },
              {
                "name": "mean",
                "type": "T",
                "description": "running (training) or estimated (testing) mean tensor of shape (C)."
              },
              {
                "name": "var",
                "type": "T",
                "description": "running (training) or estimated (testing) variance tensor of shape (C)."
              }
            ],
            "min_input": 5,
            "max_input": 5,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "The output tensor of the same shape as X"
              },
              {
                "name": "mean",
                "type": "T",
                "option": "optional",
                "description": "The running mean after the BatchNormalization operator."
              },
              {
                "name": "var",
                "type": "T",
                "option": "optional",
                "description": "The running variance after the BatchNormalization operator."
              },
              {
                "name": "saved_mean",
                "type": "T",
                "option": "optional",
                "description": "Saved mean used during training to speed up gradient computation."
              },
              {
                "name": "saved_var",
                "type": "T",
                "option": "optional",
                "description": "Saved variance used during training to speed up gradient computation."
              }
            ],
            "min_output": 1,
            "max_output": 5,
            "outputs_range": "1 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "batchnormalization",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ny = _batchnorm_test_mode(x, s, bias, mean, var).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_example\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\nepsilon = 1e-2\ny = _batchnorm_test_mode(x, s, bias, mean, var, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y],\n    name=\"test_batchnorm_epsilon\",\n)"
              },
              {
                "summary": "train",
                "code": "# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\n# using np.bool(1) while generating test data with \"'bool' object has no attribute 'dtype'\"\n# working around by using np.byte(1).astype(bool)\ntraining_mode = 1\ny, output_mean, output_var = _batchnorm_training_mode(x, s, bias, mean, var)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_example_training_mode\",\n)\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nmean = np.random.randn(3).astype(np.float32)\nvar = np.random.rand(3).astype(np.float32)\ntraining_mode = 1\nmomentum = 0.9\nepsilon = 1e-2\ny, output_mean, output_var = _batchnorm_training_mode(\n    x, s, bias, mean, var, momentum, epsilon\n)\n\nnode = onnx.helper.make_node(\n    \"BatchNormalization\",\n    inputs=[\"x\", \"s\", \"bias\", \"mean\", \"var\"],\n    outputs=[\"y\", \"output_mean\", \"output_var\"],\n    epsilon=epsilon,\n    training_mode=training_mode,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(\n    node,\n    inputs=[x, s, bias, mean, var],\n    outputs=[y, output_mean, output_var],\n    name=\"test_batchnorm_epsilon_training_mode\",\n)"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Slice_479",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "993",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "starts",
              "value": [
                {
                  "name": "1001",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 8,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "ends",
              "value": [
                {
                  "name": "1002",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 255,
                      "1": 255,
                      "2": 255,
                      "3": 255,
                      "4": 255,
                      "5": 255,
                      "6": 255,
                      "7": 127
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "axes",
              "value": [
                {
                  "name": "1000",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "steps",
              "value": [
                {
                  "name": "1003",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 1,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 0,
                      "5": 0,
                      "6": 0,
                      "7": 0
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "1004",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Slice",
            "module": "ai.onnx",
            "version": 11,
            "description": "Produces a slice of the input tensor along multiple axes. Similar to numpy:\nhttps://numpy.org/doc/stable/reference/routines.indexing.html\nSlices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end\ndimension and step for each axis in the list of axes, it uses this information to\nslice the input `data` tensor. If a negative value is passed for any of the\nstart or end indices, it represents number of elements before the end of that\ndimension. If the value passed to start or end is larger than the `n` (the\nnumber of elements in this dimension), it represents `n`. For slicing to the\nend of a dimension with unknown size, it is recommended to pass in `INT_MAX`\nwhen slicing forward and 'INT_MIN' when slicing backward.\nIf a negative value is passed for step, it represents slicing backward.\nHowever step value cannot be 0.\nIf `axes` are omitted, they are set to `[0, ..., ndim-1]`.\nIf `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`\nExample 1:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  axes = [0, 1]\n  starts = [1, 0]\n  ends = [2, 3]\n  steps = [1, 2]\n  result = [\n      [5, 7],\n  ]\nExample 2:\n  data = [\n      [1, 2, 3, 4],\n      [5, 6, 7, 8],\n  ]\n  starts = [0, 1]\n  ends = [-1, 1000]\n  result = [\n      [2, 3, 4],\n  ]\n",
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "Tensor of data to extract slices from."
              },
              {
                "name": "starts",
                "type": "Tind",
                "description": "1-D tensor of starting indices of corresponding axis in `axes`"
              },
              {
                "name": "ends",
                "type": "Tind",
                "description": "1-D tensor of ending indices (exclusive) of corresponding axis in `axes`"
              },
              {
                "name": "axes",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data)."
              },
              {
                "name": "steps",
                "type": "Tind",
                "option": "optional",
                "description": "1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1."
              }
            ],
            "min_input": 3,
            "max_input": 5,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Sliced data tensor."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "3 - 5",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain indices to integer types",
                "type_param_str": "Tind",
                "allowed_type_strs": [
                  "tensor(int32)",
                  "tensor(int64)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "slice",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\ny = x[0:3, 0:10]\nstarts = np.array([0, 0], dtype=np.int64)\nends = np.array([3, 10], dtype=np.int64)\naxes = np.array([0, 1], dtype=np.int64)\nsteps = np.array([1, 1], dtype=np.int64)\n\nexpect(\n    node, inputs=[x, starts, ends, axes, steps], outputs=[y], name=\"test_slice\"\n)"
              },
              {
                "summary": "slice_default_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node, inputs=[x, starts, ends], outputs=[y], name=\"test_slice_default_axes\"\n)"
              },
              {
                "summary": "slice_default_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_default_steps\",\n)"
              },
              {
                "summary": "slice_end_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_end_out_of_bounds\",\n)"
              },
              {
                "summary": "slice_neg",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0], dtype=np.int64)\nends = np.array([-1], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 0:-1]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg\",\n)"
              },
              {
                "summary": "slice_neg_steps",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([20, 10, 4], dtype=np.int64)\nends = np.array([0, 0, 1], dtype=np.int64)\naxes = np.array([0, 1, 2], dtype=np.int64)\nsteps = np.array([-1, -3, -2]).astype(np.int64)\ny = x[20:0:-1, 10:0:-3, 4:1:-2]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_neg_steps\",\n)"
              },
              {
                "summary": "slice_negative_axes",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([0, 0, 3], dtype=np.int64)\nends = np.array([20, 10, 4], dtype=np.int64)\naxes = np.array([0, -2, -1], dtype=np.int64)\ny = x[:, :, 3:4]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes],\n    outputs=[y],\n    name=\"test_slice_negative_axes\",\n)"
              },
              {
                "summary": "slice_start_out_of_bounds",
                "code": "node = onnx.helper.make_node(\n    \"Slice\",\n    inputs=[\"x\", \"starts\", \"ends\", \"axes\", \"steps\"],\n    outputs=[\"y\"],\n)\n\nx = np.random.randn(20, 10, 5).astype(np.float32)\nstarts = np.array([1000], dtype=np.int64)\nends = np.array([1000], dtype=np.int64)\naxes = np.array([1], dtype=np.int64)\nsteps = np.array([1], dtype=np.int64)\ny = x[:, 1000:1000]\n\nexpect(\n    node,\n    inputs=[x, starts, ends, axes, steps],\n    outputs=[y],\n    name=\"test_slice_start_out_of_bounds\",\n)"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "InstanceNormalization_482",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "1004",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "scale",
              "value": [
                {
                  "name": "1005",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "1006",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "1007",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "epsilon",
              "type": "float32",
              "value": 0.000009999999747378752
            }
          ],
          "type": {
            "name": "InstanceNormalization",
            "module": "ai.onnx",
            "version": 6,
            "description": "Carries out instance normalization as described in the paper\nhttps://arxiv.org/abs/1607.08022.\n\ny = scale * (x - mean) / sqrt(variance + epsilon) + B,\nwhere mean and variance are computed per instance per channel.\n\n",
            "attributes": [
              {
                "name": "epsilon",
                "type": "float32",
                "required": false,
                "default": 0.000009999999747378752,
                "description": "The epsilon value to use to avoid division by zero."
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              },
              {
                "name": "scale",
                "type": "T",
                "description": "The input 1-dimensional scale tensor of size C."
              },
              {
                "name": "B",
                "type": "T",
                "description": "The input 1-dimensional bias tensor of size C."
              }
            ],
            "min_input": 3,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "The output tensor of the same shape as input."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "instancenormalization",
                "code": "def _instancenorm_test_mode(x, s, bias, epsilon=1e-5):  # type: ignore\n    dims_x = len(x.shape)\n    axis = tuple(range(2, dims_x))\n    mean = np.mean(x, axis=axis, keepdims=True)\n    var = np.var(x, axis=axis, keepdims=True)\n    dim_ones = (1,) * (dims_x - 2)\n    s = s.reshape(-1, *dim_ones)\n    bias = bias.reshape(-1, *dim_ones)\n    return s * (x - mean) / np.sqrt(var + epsilon) + bias\n\n# input size: (1, 2, 1, 3)\nx = np.array([[[[-1, 0, 1]], [[2, 3, 4]]]]).astype(np.float32)\ns = np.array([1.0, 1.5]).astype(np.float32)\nbias = np.array([0, 1]).astype(np.float32)\ny = _instancenorm_test_mode(x, s, bias).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n)\n\n# output size: (1, 2, 1, 3)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_example\")\n\n# input size: (2, 3, 4, 5)\nx = np.random.randn(2, 3, 4, 5).astype(np.float32)\ns = np.random.randn(3).astype(np.float32)\nbias = np.random.randn(3).astype(np.float32)\nepsilon = 1e-2\ny = _instancenorm_test_mode(x, s, bias, epsilon).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"InstanceNormalization\",\n    inputs=[\"x\", \"s\", \"bias\"],\n    outputs=[\"y\"],\n    epsilon=epsilon,\n)\n\n# output size: (2, 3, 4, 5)\nexpect(node, inputs=[x, s, bias], outputs=[y], name=\"test_instancenorm_epsilon\")"
              }
            ],
            "category": "Normalization"
          }
        },
        {
          "name": "Concat_483",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "inputs",
              "value": [
                {
                  "name": "999",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                },
                {
                  "name": "1007",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "concat_result",
              "value": [
                {
                  "name": "1008",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "axis",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Concat",
            "module": "ai.onnx",
            "version": 11,
            "description": "Concatenate a list of tensors into a single tensor. All input tensors must have the same shape, except for the dimension size of the axis to concatenate on.",
            "attributes": [
              {
                "name": "axis",
                "type": "int64",
                "required": true,
                "description": "Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs).."
              }
            ],
            "inputs": [
              {
                "name": "inputs",
                "type": "T",
                "list": true,
                "description": "List of tensors for concatenation"
              }
            ],
            "min_input": 1,
            "max_input": 2147483647,
            "outputs": [
              {
                "name": "concat_result",
                "type": "T",
                "description": "Concatenated tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - &#8734;",
            "type_constraints": [
              {
                "description": "Constrain output types to any tensor type.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "concat",
                "code": "test_cases: dict[str, Sequence[Any]] = {\n    \"1d\": ([1, 2], [3, 4]),\n    \"2d\": ([[1, 2], [3, 4]], [[5, 6], [7, 8]]),\n    \"3d\": (\n        [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        [[[9, 10], [11, 12]], [[13, 14], [15, 16]]],\n    ),\n}\n\nfor test_case, values_ in test_cases.items():\n    values = [np.asarray(v, dtype=np.float32) for v in values_]\n    for i in range(len(values[0].shape)):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_\" + str(i),\n        )\n\n    for i in range(-len(values[0].shape), 0):\n        in_args = [\"value\" + str(k) for k in range(len(values))]\n        node = onnx.helper.make_node(\n            \"Concat\", inputs=list(in_args), outputs=[\"output\"], axis=i\n        )\n        output = np.concatenate(values, i)\n        expect(\n            node,\n            inputs=list(values),\n            outputs=[output],\n            name=\"test_concat_\" + test_case + \"_axis_negative_\" + str(abs(i)),\n        )"
              }
            ],
            "category": "Tensor"
          }
        },
        {
          "name": "Relu_484",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1008",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1009",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 6,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv_485",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1009",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "f_branch.conv_f.1.layers.0.weight",
                  "initializer": {
                    "name": "f_branch.conv_f.1.layers.0.weight",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "f_branch.conv_f.1.layers.0.bias",
                  "initializer": {
                    "name": "f_branch.conv_f.1.layers.0.bias",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float16",
                      "shape": {
                        "dimensions": [
                          1
                        ]
                      }
                    },
                    "values": {
                      "0": 189,
                      "1": 172
                    }
                  },
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "1010",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Sigmoid_486",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "1010",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "graph_output_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 6,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "graph_output_cast0",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "graph_output_cast_0",
                  "type": {
                    "dataType": "float16",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "output",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        "batch_size",
                        1,
                        "height",
                        "width"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "to",
              "type": "DataType",
              "value": "float32"
            }
          ],
          "type": {
            "name": "Cast",
            "module": "ai.onnx",
            "version": 9,
            "description": "The operator casts the elements of a given input tensor to a data type\nspecified by the 'to' argument and returns an output tensor of the same size in\nthe converted type. The 'to' argument must be one of the data types specified\nin the 'DataType' enum field in the TensorProto message.\n\nCasting from string tensor in plain (e.g., \"3.14\" and \"1000\") and scientific numeric representations\n(e.g., \"1e-5\" and \"1E8\") to float types is supported. For example, converting string \"100.5\" to an integer may\nyield result 100. There are some string literals reserved for special floating-point values;\n\"+INF\" (and \"INF\"), \"-INF\", and \"NaN\" are positive infinity, negative infinity, and not-a-number, respectively.\nAny string which can exactly match \"+INF\" in a case-insensitive way would be mapped to positive infinite. Similarly,\nthis case-insensitive rule is applied to \"INF\" and \"NaN\". When casting from numeric tensors\nto string tensors, plain floating-point representation (such as \"314.15926\") would be used.\nConverting non-numerical-literal string such as \"Hello World!\" is an undefined behavior. Cases\nof converting string representing floating-point arithmetic value, such as \"2.718\", to INT is an undefined behavior.\n\nConversion from a numerical type to any numerical type is always allowed.\nUser must be aware of precision loss and value change caused by range difference between two types.\nFor example, a 64-bit float 3.1415926459 may be round to a 32-bit float 3.141592. Similarly, converting\nan integer 36 to Boolean may produce 1 because we truncate bits which can't be stored in the targeted type.\n",
            "attributes": [
              {
                "name": "to",
                "type": "DataType",
                "required": true,
                "description": "The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto"
              }
            ],
            "inputs": [
              {
                "name": "input",
                "type": "T1",
                "description": "Input tensor to be cast."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "output",
                "type": "T2",
                "description": "Output tensor with the same shape as input with type specified by the 'to' argument"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input types. Casting from complex is not supported.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              },
              {
                "description": "Constrain output types. Casting to complex is not supported.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(bool)",
                  "tensor(string)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "cast",
                "code": "shape = (3, 4)\ntest_cases = [\n    (\"FLOAT\", \"FLOAT16\"),\n    (\"FLOAT\", \"DOUBLE\"),\n    (\"FLOAT16\", \"FLOAT\"),\n    (\"FLOAT16\", \"DOUBLE\"),\n    (\"DOUBLE\", \"FLOAT\"),\n    (\"DOUBLE\", \"FLOAT16\"),\n    (\"FLOAT\", \"STRING\"),\n    (\"STRING\", \"FLOAT\"),\n    (\"FLOAT\", \"BFLOAT16\"),\n    (\"BFLOAT16\", \"FLOAT\"),\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT\"),\n    (\"FLOAT8E4M3FN\", \"FLOAT16\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E4M3FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT8E5M2\", \"FLOAT\"),\n    (\"FLOAT8E5M2\", \"FLOAT16\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT\"),\n    (\"FLOAT8E5M2FNUZ\", \"FLOAT16\"),\n    (\"FLOAT\", \"UINT4\"),\n    (\"FLOAT16\", \"UINT4\"),\n    (\"FLOAT\", \"INT4\"),\n    (\"FLOAT16\", \"INT4\"),\n    (\"UINT4\", \"FLOAT\"),\n    (\"UINT4\", \"FLOAT16\"),\n    (\"UINT4\", \"UINT8\"),\n    (\"INT4\", \"FLOAT\"),\n    (\"INT4\", \"FLOAT16\"),\n    (\"INT4\", \"INT8\"),\n    (\"FLOAT4E2M1\", \"FLOAT\"),\n    (\"FLOAT4E2M1\", \"FLOAT16\"),\n    (\"FLOAT\", \"FLOAT4E2M1\"),\n    (\"FLOAT16\", \"FLOAT4E2M1\"),\n]\n\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\nvect_float32_to_uint4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=False)\n)\nvect_float32_to_int4 = np.vectorize(\n    lambda x: subbyte.float32_to_4bit_unpacked(x, signed=True)\n)\n\nf8_types = (\"FLOAT8E4M3FN\", \"FLOAT8E4M3FNUZ\", \"FLOAT8E5M2\", \"FLOAT8E5M2FNUZ\")\n\nfor from_type, to_type in test_cases:\n    input_type_proto = None\n    output_type_proto = None\n    if from_type == \"BFLOAT16\" or to_type == \"BFLOAT16\":\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.float32,\n        )\n        little_endisan = sys.byteorder == \"little\"\n        np_uint16_view = np_fp32.view(dtype=np.uint16)\n        np_bfp16 = (\n            np_uint16_view[1::2] if little_endisan else np_uint16_view[0::2]\n        )\n        if to_type == \"BFLOAT16\":\n            assert from_type == \"FLOAT\"\n            input = np_fp32.reshape([3, 4])\n            output = np_bfp16.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), output.shape\n            )\n        else:\n            assert to_type == \"FLOAT\"\n            input = np_bfp16.reshape([3, 4])\n            # convert bfloat to FLOAT\n            np_fp32_zeros = np.zeros((len(np_bfp16) * 2,), dtype=np.uint16)\n            if little_endisan:\n                np_fp32_zeros[1::2] = np_bfp16\n            else:\n                np_fp32_zeros[0::2] = np_bfp16\n            np_fp32_from_bfloat = np_fp32_zeros.view(dtype=np.float32)\n            output = np_fp32_from_bfloat.reshape([3, 4])\n            input_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.BFLOAT16), input.shape\n            )\n            output_type_proto = onnx.helper.make_tensor_type_proto(\n                int(TensorProto.FLOAT), output.shape\n            )\n    elif from_type in f8_types or to_type in f8_types:\n        np_fp32 = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.7229038\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-0.0000001\",\n                \"0.0000001\",\n                \"-1000000\",\n            ],\n            dtype=np.float32,\n        )\n\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FN\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FN, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E4M3FNUZ\":\n            input_values = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(np_fp32, uz=True), uz=True\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E4M3FNUZ, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32)\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2, [3, 5], input_values.tolist()\n            )\n        elif from_type == \"FLOAT8E5M2FNUZ\":\n            input_values = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(np_fp32, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT8E5M2FNUZ, [3, 5], input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type == \"FLOAT8E4M3FN\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values)\n            )\n        elif to_type == \"FLOAT8E4M3FNUZ\":\n            expected = float8e4m3_to_float32(\n                vect_float32_to_float8e4m3(input_values, uz=True), uz=True\n            )\n        elif to_type == \"FLOAT8E5M2\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values)\n            )\n        elif to_type == \"FLOAT8E5M2FNUZ\":\n            expected = float8e5m2_to_float32(\n                vect_float32_to_float8e5m2(input_values, fn=True, uz=True),\n                fn=True,\n                uz=True,\n            )\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16).astype(np.float32)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"x\", getattr(TensorProto, to_type), [3, 5], expected.tolist()\n        )\n        output = expected_tensor\n    elif from_type in (\"UINT4\", \"INT4\") or to_type in (\"UINT4\", \"INT4\"):\n        np_fp32 = np.arange(-9, 16).astype(np.float32)\n        input_shape = (5, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"UINT4\":\n            input_values = vect_float32_to_uint4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.UINT4, input_shape, input_values.tolist()\n            )\n        elif from_type == \"INT4\":\n            input_values = vect_float32_to_int4(np_fp32)\n            input = make_tensor(\n                \"x\", TensorProto.INT4, input_shape, input_values.tolist()\n            )\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        if to_type == \"UINT4\":\n            expected = vect_float32_to_uint4(input_values).astype(custom.uint4)\n        elif to_type == \"INT4\":\n            expected = vect_float32_to_int4(input_values).astype(custom.int4)\n        elif to_type == \"FLOAT16\":\n            expected = input_values.astype(np.float16)\n        elif to_type == \"FLOAT\":\n            expected = input_values\n        elif to_type == \"UINT8\":\n            expected = input_values.astype(np.uint8)\n        elif to_type == \"INT8\":\n            expected = input_values.astype(np.int8)\n        else:\n            raise ValueError(\n                \"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected_tensor = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n        output = expected_tensor\n        input_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, from_type), input_shape\n        )\n        output_type_proto = onnx.helper.make_tensor_type_proto(\n            getattr(TensorProto, to_type), input_shape\n        )\n    elif from_type == \"FLOAT4E2M1\" or to_type == \"FLOAT4E2M1\":\n        np_fp32 = np.array(\n            [\n                \"0.48\",\n                \"0.25\",\n                \"1.05\",\n                \"-3.5\",\n                \"-8\",\n                \"9\",\n                \"1000000\",\n                \"1e-7\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n                \"-4\",\n                \"0.01\",\n                \"-0.0\",\n            ],\n            dtype=np.float32,\n        )\n        input_shape = (3, 5)\n        if from_type == \"FLOAT\":\n            input_values = np_fp32\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT16\":\n            input_values = np_fp32.astype(np.float16).astype(np.float32)\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT16, input_shape, input_values.tolist()\n            )\n        elif from_type == \"FLOAT4E2M1\":\n            input = make_tensor(\n                \"x\", TensorProto.FLOAT4E2M1, input_shape, np_fp32.tolist()\n            )\n        else:\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n\n        if to_type not in (\"FLOAT\", \"FLOAT16\", \"FLOAT4E2M1\"):\n            raise ValueError(\n                f\"Conversion from {from_type} to {to_type} is not tested.\"\n            )\n        expected = unpacked_float4e2m1_to_float32(\n            subbyte.float32_to_float4e2m1_unpacked(np_fp32)\n        )\n        output = make_tensor(\n            \"y\", getattr(TensorProto, to_type), input_shape, expected.tolist()\n        )\n    elif from_type != \"STRING\":\n        input = np.random.random_sample(shape).astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, from_type))\n        )\n        if to_type == \"STRING\":\n            # Converting input to str, then give it object dtype for generating script\n            ss = []\n            for i in input.flatten():\n                s = str(i).encode(\"utf-8\")\n                su = s.decode(\"utf-8\")\n                ss.append(su)\n\n            output = np.array(ss).astype(object).reshape([3, 4])\n        else:\n            output = input.astype(\n                helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n            )\n    else:\n        input = np.array(\n            [\n                \"0.47892547\",\n                \"0.48033667\",\n                \"0.49968487\",\n                \"0.81910545\",\n                \"0.47031248\",\n                \"0.816468\",\n                \"0.21087195\",\n                \"0.7229038\",\n                \"NaN\",\n                \"INF\",\n                \"+INF\",\n                \"-INF\",\n            ],\n            dtype=np.dtype(object),\n        ).reshape([3, 4])\n        output = input.astype(\n            helper.tensor_dtype_to_np_dtype(getattr(TensorProto, to_type))\n        )\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n    )\n    if input_type_proto and output_type_proto:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n            input_type_protos=[input_type_proto],\n            output_type_protos=[output_type_proto],\n        )\n    else:\n        expect(\n            node,\n            inputs=[input],\n            outputs=[output],\n            name=\"test_cast_\" + from_type + \"_to_\" + to_type,\n        )"
              },
              {
                "summary": "saturate_false",
                "code": "test_cases = [\n    (\"FLOAT\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FN\"),\n    (\"FLOAT\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E4M3FNUZ\"),\n    (\"FLOAT\", \"FLOAT8E5M2\"),\n    (\"FLOAT16\", \"FLOAT8E5M2\"),\n    (\"FLOAT\", \"FLOAT8E5M2FNUZ\"),\n    (\"FLOAT16\", \"FLOAT8E5M2FNUZ\"),\n]\nvect_float32_to_float8e4m3 = np.vectorize(float32_to_float8e4m3)\nvect_float32_to_float8e5m2 = np.vectorize(float32_to_float8e5m2)\n\nfor from_type, to_type in test_cases:\n    np_fp32 = np.array(\n        [\n            \"0.47892547\",\n            \"0.48033667\",\n            \"0.49968487\",\n            \"0.81910545\",\n            \"0.47031248\",\n            \"0.7229038\",\n            \"1000000\",\n            \"1e-7\",\n            \"NaN\",\n            \"INF\",\n            \"+INF\",\n            \"-INF\",\n            \"-0.0000001\",\n            \"0.0000001\",\n            \"-1000000\",\n        ],\n        dtype=np.float32,\n    )\n\n    if from_type == \"FLOAT\":\n        input_values = np_fp32\n        input = make_tensor(\"x\", TensorProto.FLOAT, [3, 5], np_fp32.tolist())\n    elif from_type == \"FLOAT16\":\n        input_values = np_fp32.astype(np.float16).astype(np.float32)\n        input = make_tensor(\n            \"x\", TensorProto.FLOAT16, [3, 5], input_values.tolist()\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    if to_type == \"FLOAT8E4M3FN\":\n        expected = vect_float32_to_float8e4m3(input_values, saturate=False)\n    elif to_type == \"FLOAT8E4M3FNUZ\":\n        expected = vect_float32_to_float8e4m3(\n            input_values, uz=True, saturate=False\n        )\n    elif to_type == \"FLOAT8E5M2\":\n        expected = vect_float32_to_float8e5m2(input_values, saturate=False)\n    elif to_type == \"FLOAT8E5M2FNUZ\":\n        expected = vect_float32_to_float8e5m2(\n            input_values, fn=True, uz=True, saturate=False\n        )\n    else:\n        raise ValueError(\n            \"Conversion from {from_type} to {to_type} is not tested.\"\n        )\n\n    ivals = bytes([int(i) for i in expected])\n    tensor = TensorProto()\n    tensor.data_type = getattr(TensorProto, to_type)\n    tensor.name = \"x\"\n    tensor.dims.extend([3, 5])\n    field = tensor_dtype_to_field(tensor.data_type)\n    getattr(tensor, field).extend(ivals)\n\n    output = tensor\n\n    node = onnx.helper.make_node(\n        \"Cast\",\n        inputs=[\"input\"],\n        outputs=[\"output\"],\n        to=getattr(TensorProto, to_type),\n        saturate=0,\n    )\n    expect(\n        node,\n        inputs=[input],\n        outputs=[output],\n        name=\"test_cast_no_saturate_\" + from_type + \"_to_\" + to_type,\n    )"
              }
            ]
          }
        }
      ]
    }
  ]
}