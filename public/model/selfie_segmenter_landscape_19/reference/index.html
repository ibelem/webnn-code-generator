<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Test SelfieSegmenterLandscape19 in nchw and nhwc layouts</title>
</head>
<body>
  <h1>Test SelfieSegmenterLandscape19.js in nchw and nhwc layouts</h1>
  <label for="deviceType">Device:</label>
  <select id="deviceType">
    <option value="cpu">CPU</option>
    <option value="gpu" selected>GPU</option>
    <option value="npu">NPU</option>
  </select>
  <label for="numRuns">#Runs:</label>
  <input type="number" id="numRuns" value="1" min="1" style="width: 4em;">
  <button id="run-btn">Build & Run Model</button>
  <pre id="output"></pre>
  <script type="module">
    import { SelfieSegmenterLandscape19Nchw } from './selfie_segmenter_landscape_19_nchw.js';
    import { SelfieSegmenterLandscape19Nhwc } from './selfie_segmenter_landscape_19_nhwc.js';

    const output = document.getElementById('output');
    const deviceTypeSelect = document.getElementById('deviceType');

    // Add event listener for deviceType change
    deviceTypeSelect.addEventListener('change', async () => {
      const deviceType = deviceTypeSelect.value || 'gpu';
      let preferredInputLayout = 'nchw';
      if (navigator.ml && navigator.ml.createContext) {
        try {
          const tmpContext = await navigator.ml.createContext({ deviceType });
          preferredInputLayout = tmpContext.opSupportLimits().preferredInputLayout;
        } catch (e) {}
      }
      output.textContent = `Selected ${deviceType} Â· preferredInputLayout: ${preferredInputLayout}
`;
    });

    document.getElementById('run-btn').onclick = async () => {
      output.textContent = 'Building model...\n';
      try {
        const deviceType = deviceTypeSelect.value || 'gpu';
        let layout = 'nchw';
        if (navigator.ml && navigator.ml.createContext) {
          try {
            const tmpContext = await navigator.ml.createContext({ deviceType });
            layout = tmpContext.opSupportLimits().preferredInputLayout;
          } catch (e) {}
        }
        let model;
        if (layout === 'nchw') {
            model = new SelfieSegmenterLandscape19Nchw();
        } else {
            model = new SelfieSegmenterLandscape19Nhwc();
        }
        const t0 = performance.now();
        await model.build({ deviceType: deviceType });
        const t1 = performance.now();
        output.textContent += `Model built successfully. Build latency: ${(t1 - t0).toFixed(2)} ms\n`;

        // Output input tensor info
        output.textContent += '\nInput tensors:\n';
        for (const name in model.inputTensors_) {
          const tensor = model.inputTensors_[name];
          output.textContent += `  ${name}: shape=[${tensor.shape}], dataType=${tensor.dataType}\n`;
        }

        // Output output tensor info
        output.textContent += '\nOutput tensors:\n';
        for (const name in model.outputTensors_) {
          const tensor = model.outputTensors_[name];
          output.textContent += `  ${name}: shape=[${tensor.shape}], dataType=${tensor.dataType}\n`;
        }
        output.textContent += '\n';

        // Prepare dummy input data for testing (random values)
        const inputs = {};
        for (const name in model.inputTensors_) {
          const tensor = model.inputTensors_[name];
          let typedArrayCtor = Float32Array;
          switch (tensor.dataType) {
            case 'float32': typedArrayCtor = Float32Array; break;
            case 'uint8': typedArrayCtor = Uint8Array; break;
            case 'int8': typedArrayCtor = Int8Array; break;
            case 'uint16': typedArrayCtor = Uint16Array; break;
            case 'int16': typedArrayCtor = Int16Array; break;
            case 'int32': typedArrayCtor = Int32Array; break;
            case 'int64': typedArrayCtor = BigInt64Array; break;
            case 'float16': typedArrayCtor = Float16Array; break;
            case 'float64': typedArrayCtor = Float64Array; break;
            case 'uint32': typedArrayCtor = Uint32Array; break;
            case 'uint64': typedArrayCtor = BigUint64Array; break;
            default: throw new Error(`Unhandled input dataType: ${tensor.dataType}`);
          }
          const size = tensor.shape.reduce((a, b) => a * b, 1);
          const arr = new typedArrayCtor(size);
          // Fill with random values
          if (typedArrayCtor === Float32Array || typedArrayCtor === Float64Array) {
            for (let i = 0; i < size; ++i) arr[i] = Math.random();
          } else if (typedArrayCtor.BYTES_PER_ELEMENT === 8) {
            // BigInt64Array/BigUint64Array
            for (let i = 0; i < size; ++i) arr[i] = BigInt(Math.floor(Math.random() * 100));
          } else {
            for (let i = 0; i < size; ++i) arr[i] = Math.floor(Math.random() * 100);
          }
          inputs[name] = arr;
        }

        output.textContent += 'Running inference...\n';
        // Get number of runs from input
        let numRuns = parseInt(document.getElementById('numRuns').value) || 1;
        if (numRuns < 1) numRuns = 1;
        // Time model.run and print median inference latency
        const latencies = [];
        let results = null;
        for (let i = 0; i < numRuns; ++i) {
          const t0 = performance.now();
          results = await model.run(inputs);
          const t1 = performance.now();
          latencies.push(t1 - t0);
        }
        latencies.sort((a, b) => a - b);
        const median = latencies[Math.floor(latencies.length / 2)];
        output.textContent += `Median inference latency (${numRuns} runs): ${median.toFixed(2)} ms\n`;
        output.textContent += '\n';
        output.textContent += 'Inference results:\n' + JSON.stringify(results, null, 2);
      } catch (e) {
        output.textContent += 'Error: ' + e;
      }
    };
  </script>
</body>
</html>